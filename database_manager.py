#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡æ–™åº«ç®¡ç†æ¨¡çµ„ - SQLite ç‰ˆæœ¬ (æ”¯æ´å¤šæºæµ·äº‹è­¦å‘Š)
"""

import sqlite3
from datetime import datetime, timedelta
import pandas as pd
import json
import os

class DatabaseManager:
    def __init__(self, db_name=None):
        """åˆå§‹åŒ– SQLite è³‡æ–™åº«"""
        # å¾ç’°å¢ƒè®Šæ•¸è®€å–æˆ–ä½¿ç”¨é è¨­å€¼
        if db_name is None:
            from dotenv import load_dotenv
            load_dotenv()
            db_name = os.getenv('DB_FILE_PATH', 'navigation_warnings.db')
        
        self.db_name = db_name
        print(f"ğŸ“ ä½¿ç”¨ SQLite è³‡æ–™åº«: {self.db_name}")
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ– SQLite è³‡æ–™åº«"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        # å»ºç«‹ä¸»è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS warnings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                maritime_bureau TEXT NOT NULL,
                title TEXT NOT NULL,
                link TEXT,
                publish_time TEXT,
                keywords_matched TEXT,
                scrape_time TEXT NOT NULL,
                coordinates TEXT,
                source_type TEXT DEFAULT 'CN_MSA',
                source_country TEXT DEFAULT 'CN',
                is_notified INTEGER DEFAULT 0,
                notified_time TEXT,
                created_at TEXT,
                updated_at TEXT,
                UNIQUE(maritime_bureau, title, publish_time, source_type)
            )
        ''')
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ–°å¢æ¬„ä½ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
        cursor.execute("PRAGMA table_info(warnings)")
        columns = [column[1] for column in cursor.fetchall()]
        
        # æ–°å¢å¤šæºæ”¯æ´æ¬„ä½
        if 'source_type' not in columns:
            print("ğŸ”„ æ–°å¢ source_type æ¬„ä½...")
            cursor.execute('ALTER TABLE warnings ADD COLUMN source_type TEXT DEFAULT "CN_MSA"')
            conn.commit()
            print("âœ… source_type æ¬„ä½æ–°å¢å®Œæˆ")
        
        if 'source_country' not in columns:
            print("ğŸ”„ æ–°å¢ source_country æ¬„ä½...")
            cursor.execute('ALTER TABLE warnings ADD COLUMN source_country TEXT DEFAULT "CN"')
            conn.commit()
            print("âœ… source_country æ¬„ä½æ–°å¢å®Œæˆ")
        
        if 'coordinates' not in columns:
            print("ğŸ”„ æ–°å¢ coordinates æ¬„ä½...")
            cursor.execute('ALTER TABLE warnings ADD COLUMN coordinates TEXT')
            conn.commit()
            print("âœ… coordinates æ¬„ä½æ–°å¢å®Œæˆ")
        
        if 'created_at' not in columns:
            print("ğŸ”„ æ–°å¢ created_at æ¬„ä½...")
            cursor.execute('ALTER TABLE warnings ADD COLUMN created_at TEXT')
            conn.commit()
            print("âœ… created_at æ¬„ä½æ–°å¢å®Œæˆ")
        
        if 'updated_at' not in columns:
            print("ğŸ”„ æ–°å¢ updated_at æ¬„ä½...")
            cursor.execute('ALTER TABLE warnings ADD COLUMN updated_at TEXT')
            conn.commit()
            print("âœ… updated_at æ¬„ä½æ–°å¢å®Œæˆ")
        
        # æ›´æ–°ç¾æœ‰è³‡æ–™çš„ source_type å’Œ source_countryï¼ˆå¦‚æœç‚ºç©ºï¼‰
        cursor.execute('''
            UPDATE warnings 
            SET source_type = 'CN_MSA', source_country = 'CN'
            WHERE source_type IS NULL OR source_type = ''
        ''')
        conn.commit()
        
        # å»ºç«‹ç´¢å¼•ä»¥æå‡æŸ¥è©¢æ•ˆèƒ½
        indexes = [
            ('idx_is_notified', 'is_notified'),
            ('idx_scrape_time', 'scrape_time'),
            ('idx_maritime_bureau', 'maritime_bureau'),
            ('idx_coordinates', 'coordinates'),
            ('idx_source_type', 'source_type'),
            ('idx_source_country', 'source_country'),
            ('idx_source_bureau', 'source_type, maritime_bureau')
        ]
        
        for index_name, index_columns in indexes:
            cursor.execute(f'''
                CREATE INDEX IF NOT EXISTS {index_name} 
                ON warnings({index_columns})
            ''')
        
        conn.commit()
        conn.close()
        print(f"âœ… SQLite è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ")
    
    def save_warning(self, data, source_type="CN_MSA"):
        """
        å„²å­˜è­¦å‘Šè³‡æ–™åˆ°è³‡æ–™åº« (æ”¯æ´å¤šæº)
        data: tuple (maritime_bureau, title, link, publish_time, keywords_matched, scrape_time, coordinates)
        source_type: 'CN_MSA' (ä¸­åœ‹æµ·äº‹å±€) æˆ– 'TW_MPB' (å°ç£èˆªæ¸¯å±€)
        è¿”å›: (is_new: bool, warning_id: int or None)
        """
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        try:
            # è™•ç†åº§æ¨™è³‡æ–™
            coordinates = data[6] if len(data) > 6 else None
            
            # å¦‚æœ coordinates æ˜¯ listï¼Œè½‰æ›ç‚º JSON å­—ä¸²
            if isinstance(coordinates, list):
                coordinates = json.dumps(coordinates, ensure_ascii=False)
            
            # æ ¹æ“šä¾†æºé¡å‹è¨­å®šåœ‹å®¶ä»£ç¢¼
            source_country = "TW" if source_type == "TW_MPB" else "CN"
            
            # ç•¶å‰æ™‚é–“
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            cursor.execute('''
                INSERT OR IGNORE INTO warnings 
                (maritime_bureau, title, link, publish_time, keywords_matched, scrape_time, 
                 coordinates, source_type, source_country, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (data[0], data[1], data[2], data[3], data[4], data[5], 
                  coordinates, source_type, source_country, current_time, current_time))
            
            conn.commit()
            
            # æª¢æŸ¥æ˜¯å¦çœŸçš„æ’å…¥äº†æ–°è³‡æ–™
            if cursor.rowcount > 0:
                warning_id = cursor.lastrowid
                source_flag = "ğŸ‡¹ğŸ‡¼" if source_type == "TW_MPB" else "ğŸ‡¨ğŸ‡³"
                print(f"  ğŸ’¾ {source_flag} æ–°è³‡æ–™å·²å„²å­˜ (ID: {warning_id})")
                return True, warning_id
            else:
                # è³‡æ–™å·²å­˜åœ¨ï¼Œç²å–ç¾æœ‰ ID ä¸¦æ›´æ–°åº§æ¨™ï¼ˆå¦‚æœæœ‰æ–°åº§æ¨™ï¼‰
                cursor.execute('''
                    SELECT id, coordinates FROM warnings 
                    WHERE maritime_bureau=? AND title=? AND publish_time=? AND source_type=?
                ''', (data[0], data[1], data[3], source_type))
                result = cursor.fetchone()
                
                if result:
                    existing_id = result[0]
                    existing_coords = result[1]
                    
                    # å¦‚æœæœ‰æ–°åº§æ¨™ä¸”èˆŠè³‡æ–™æ²’æœ‰åº§æ¨™ï¼Œå‰‡æ›´æ–°
                    if coordinates and not existing_coords:
                        cursor.execute('''
                            UPDATE warnings 
                            SET coordinates = ?, updated_at = ?
                            WHERE id = ?
                        ''', (coordinates, current_time, existing_id))
                        conn.commit()
                        source_flag = "ğŸ‡¹ğŸ‡¼" if source_type == "TW_MPB" else "ğŸ‡¨ğŸ‡³"
                        print(f"  ğŸ”„ {source_flag} å·²æ›´æ–°åº§æ¨™è³‡æ–™ (ID: {existing_id})")
                    
                    return False, existing_id
                
                return False, None
                
        except Exception as e:
            print(f"âŒ è³‡æ–™åº«å„²å­˜éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return False, None
        finally:
            conn.close()
    
    def get_unnotified_warnings(self, source_type=None):
        """
        ç²å–å°šæœªé€šçŸ¥çš„è­¦å‘Šï¼ˆå«åº§æ¨™ï¼‰
        source_type: None (å…¨éƒ¨), 'CN_MSA', 'TW_MPB'
        """
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        try:
            if source_type:
                cursor.execute('''
                    SELECT id, maritime_bureau, title, link, publish_time, 
                           keywords_matched, scrape_time, coordinates, source_type, source_country
                    FROM warnings
                    WHERE is_notified = 0 AND source_type = ?
                    ORDER BY scrape_time DESC
                ''', (source_type,))
            else:
                cursor.execute('''
                    SELECT id, maritime_bureau, title, link, publish_time, 
                           keywords_matched, scrape_time, coordinates, source_type, source_country
                    FROM warnings
                    WHERE is_notified = 0
                    ORDER BY scrape_time DESC
                ''')
            
            results = cursor.fetchall()
            return results
            
        except Exception as e:
            print(f"âŒ æŸ¥è©¢æœªé€šçŸ¥è­¦å‘Šæ™‚å‡ºéŒ¯: {e}")
            return []
        finally:
            conn.close()
    
    def mark_as_notified(self, warning_id):
        """æ¨™è¨˜è­¦å‘Šç‚ºå·²é€šçŸ¥"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        try:
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            cursor.execute('''
                UPDATE warnings
                SET is_notified = 1, notified_time = ?, updated_at = ?
                WHERE id = ?
            ''', (current_time, current_time, warning_id))
            
            conn.commit()
            
            # æª¢æŸ¥æ˜¯å¦çœŸçš„æ›´æ–°äº†
            if cursor.rowcount == 0:
                print(f"âš ï¸ è­¦å‘Š ID {warning_id} ä¸å­˜åœ¨æˆ–å·²æ¨™è¨˜")
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨™è¨˜é€šçŸ¥ç‹€æ…‹æ™‚å‡ºéŒ¯: {e}")
            return False
        finally:
            conn.close()
    
    def get_all_warnings(self, limit=None, source_type=None):
        """
        ç²å–æ‰€æœ‰è­¦å‘Š
        source_type: None (å…¨éƒ¨), 'CN_MSA', 'TW_MPB'
        """
        conn = sqlite3.connect(self.db_name)
        
        try:
            if source_type:
                query = 'SELECT * FROM warnings WHERE source_type = ? ORDER BY scrape_time DESC'
                params = (source_type,)
            else:
                query = 'SELECT * FROM warnings ORDER BY scrape_time DESC'
                params = ()
            
            if limit:
                query += f' LIMIT {limit}'
            
            if params:
                df = pd.read_sql_query(query, conn, params=params)
            else:
                df = pd.read_sql_query(query, conn)
            
            return df
            
        except Exception as e:
            print(f"âŒ æŸ¥è©¢æ‰€æœ‰è­¦å‘Šæ™‚å‡ºéŒ¯: {e}")
            return pd.DataFrame()
        finally:
            conn.close()
    
    def get_warnings_with_coordinates(self, source_type=None):
        """
        ç²å–æ‰€æœ‰å«åº§æ¨™çš„è­¦å‘Š
        source_type: None (å…¨éƒ¨), 'CN_MSA', 'TW_MPB'
        """
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        try:
            if source_type:
                cursor.execute('''
                    SELECT id, maritime_bureau, title, link, publish_time, 
                           keywords_matched, scrape_time, coordinates, source_type, source_country
                    FROM warnings
                    WHERE coordinates IS NOT NULL AND coordinates != '' AND coordinates != '[]'
                    AND source_type = ?
                    ORDER BY scrape_time DESC
                ''', (source_type,))
            else:
                cursor.execute('''
                    SELECT id, maritime_bureau, title, link, publish_time, 
                           keywords_matched, scrape_time, coordinates, source_type, source_country
                    FROM warnings
                    WHERE coordinates IS NOT NULL AND coordinates != '' AND coordinates != '[]'
                    ORDER BY scrape_time DESC
                ''')
            
            results = cursor.fetchall()
            
            # è§£æåº§æ¨™ JSON
            parsed_results = []
            for row in results:
                row_list = list(row)
                try:
                    if row_list[7]:  # coordinates æ¬„ä½
                        row_list[7] = json.loads(row_list[7])
                except:
                    row_list[7] = []
                parsed_results.append(tuple(row_list))
            
            return parsed_results
            
        except Exception as e:
            print(f"âŒ æŸ¥è©¢å«åº§æ¨™è­¦å‘Šæ™‚å‡ºéŒ¯: {e}")
            return []
        finally:
            conn.close()
    
    def export_to_excel(self, filename=None, source_type=None):
        """
        åŒ¯å‡ºè³‡æ–™åˆ° Excelï¼ˆå«åº§æ¨™è§£æå’Œå¤šæºæ”¯æ´ï¼‰
        source_type: None (å…¨éƒ¨), 'CN_MSA', 'TW_MPB'
        """
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            source_suffix = f"_{source_type}" if source_type else "_ALL"
            filename = f'navigation_warnings{source_suffix}_{timestamp}.xlsx'
        
        df = self.get_all_warnings(source_type=source_type)
        
        if not df.empty:
            try:
                # è§£æåº§æ¨™æ¬„ä½
                def parse_coordinates(coord_str):
                    if pd.isna(coord_str) or coord_str == '' or coord_str == '[]':
                        return 'ç„¡åº§æ¨™'
                    try:
                        coords = json.loads(coord_str)
                        if not coords:
                            return 'ç„¡åº§æ¨™'
                        # æ ¼å¼åŒ–é¡¯ç¤ºå‰3å€‹åº§æ¨™
                        coord_text = '\n'.join([f"({c[0]:.4f}Â°, {c[1]:.4f}Â°)" for c in coords[:3]])
                        if len(coords) > 3:
                            coord_text += f"\n...é‚„æœ‰ {len(coords)-3} å€‹åº§æ¨™"
                        return coord_text
                    except:
                        return 'åº§æ¨™æ ¼å¼éŒ¯èª¤'
                
                # ä¾†æºæ¨™è¨˜
                def format_source(row):
                    if row['source_type'] == 'TW_MPB':
                        return f"ğŸ‡¹ğŸ‡¼ å°ç£èˆªæ¸¯å±€"
                    else:
                        return f"ğŸ‡¨ğŸ‡³ ä¸­åœ‹æµ·äº‹å±€"
                
                df['coordinates_display'] = df['coordinates'].apply(parse_coordinates)
                df['source_display'] = df.apply(format_source, axis=1)
                
                # é‡æ–°æ’åºæ¬„ä½
                columns_order = [
                    'id', 'source_display', 'maritime_bureau', 'title', 'link', 'publish_time',
                    'keywords_matched', 'coordinates_display', 'scrape_time',
                    'is_notified', 'notified_time'
                ]
                
                # åªé¸æ“‡å­˜åœ¨çš„æ¬„ä½
                columns_order = [col for col in columns_order if col in df.columns]
                df = df[columns_order]
                
                # é‡æ–°å‘½åæ¬„ä½ï¼ˆä¸­æ–‡ï¼‰
                df.rename(columns={
                    'id': 'ID',
                    'source_display': 'è³‡æ–™ä¾†æº',
                    'maritime_bureau': 'ç™¼å¸ƒå–®ä½',
                    'title': 'æ¨™é¡Œ',
                    'link': 'é€£çµ',
                    'publish_time': 'ç™¼å¸ƒæ™‚é–“',
                    'keywords_matched': 'é—œéµå­—',
                    'coordinates_display': 'åº§æ¨™',
                    'scrape_time': 'æŠ“å–æ™‚é–“',
                    'is_notified': 'å·²é€šçŸ¥',
                    'notified_time': 'é€šçŸ¥æ™‚é–“'
                }, inplace=True)
                
                # å„²å­˜åˆ° Excel
                with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='èˆªè¡Œè­¦å‘Š')
                    
                    # èª¿æ•´æ¬„å¯¬
                    worksheet = writer.sheets['èˆªè¡Œè­¦å‘Š']
                    from openpyxl.utils import get_column_letter
                    for idx, col in enumerate(df.columns, 1):
                        max_length = max(
                            df[col].astype(str).apply(len).max(),
                            len(col)
                        )
                        column_letter = get_column_letter(idx)
                        worksheet.column_dimensions[column_letter].width = min(max_length + 2, 50)
                
                source_desc = {
                    'CN_MSA': 'ä¸­åœ‹æµ·äº‹å±€',
                    'TW_MPB': 'å°ç£èˆªæ¸¯å±€',
                    None: 'å¤šæºæ•´åˆ'
                }.get(source_type, 'æœªçŸ¥ä¾†æº')
                
                print(f"âœ… {source_desc} Excel æª”æ¡ˆå·²å„²å­˜: {filename}")
                return True
                
            except Exception as e:
                print(f"âŒ Excel åŒ¯å‡ºå¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
                return False
        else:
            print("âš ï¸ æ²’æœ‰è³‡æ–™å¯ä»¥åŒ¯å‡º")
            return False
    
    def get_statistics(self):
        """ç²å–çµ±è¨ˆè³‡è¨Šï¼ˆå«å¤šæºçµ±è¨ˆï¼‰"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        try:
            # ç¸½è­¦å‘Šæ•¸
            cursor.execute('SELECT COUNT(*) FROM warnings')
            total = cursor.fetchone()[0]
            
            # å„ä¾†æºçµ±è¨ˆ
            cursor.execute('''
                SELECT source_type, source_country, COUNT(*) as count
                FROM warnings
                GROUP BY source_type, source_country
                ORDER BY count DESC
            ''')
            source_stats = cursor.fetchall()
            
            # å·²é€šçŸ¥æ•¸
            cursor.execute('SELECT COUNT(*) FROM warnings WHERE is_notified = 1')
            notified = cursor.fetchone()[0]
            
            # æœªé€šçŸ¥æ•¸
            cursor.execute('SELECT COUNT(*) FROM warnings WHERE is_notified = 0')
            unnotified = cursor.fetchone()[0]
            
            # å«åº§æ¨™æ•¸
            cursor.execute('''
                SELECT COUNT(*) FROM warnings 
                WHERE coordinates IS NOT NULL AND coordinates != '' AND coordinates != '[]'
            ''')
            with_coords = cursor.fetchone()[0]
            
            # å„ä¾†æºå«åº§æ¨™çµ±è¨ˆ
            cursor.execute('''
                SELECT source_type, COUNT(*) as count
                FROM warnings 
                WHERE coordinates IS NOT NULL AND coordinates != '' AND coordinates != '[]'
                GROUP BY source_type
                ORDER BY count DESC
            ''')
            coords_by_source = cursor.fetchall()
            
            # ç¸½åº§æ¨™é»æ•¸
            cursor.execute('''
                SELECT coordinates FROM warnings 
                WHERE coordinates IS NOT NULL AND coordinates != '' AND coordinates != '[]'
            ''')
            total_coord_points = 0
            for row in cursor.fetchall():
                try:
                    coords = json.loads(row[0])
                    total_coord_points += len(coords)
                except:
                    pass
            
            # å„æµ·äº‹å±€çµ±è¨ˆï¼ˆæŒ‰ä¾†æºåˆ†çµ„ï¼‰
            cursor.execute('''
                SELECT source_type, maritime_bureau, COUNT(*) as count
                FROM warnings
                GROUP BY source_type, maritime_bureau
                ORDER BY source_type, count DESC
            ''')
            bureau_stats = cursor.fetchall()
            
            # å„é—œéµå­—çµ±è¨ˆ
            cursor.execute('''
                SELECT keywords_matched, COUNT(*) as count
                FROM warnings
                WHERE keywords_matched IS NOT NULL AND keywords_matched != ''
                GROUP BY keywords_matched
                ORDER BY count DESC
            ''')
            keyword_stats = cursor.fetchall()
            
            # æœ€è¿‘7å¤©çµ±è¨ˆï¼ˆæŒ‰ä¾†æºåˆ†çµ„ï¼‰
            cursor.execute('''
                SELECT DATE(scrape_time) as date, source_type, COUNT(*) as count
                FROM warnings
                WHERE scrape_time >= datetime('now', '-7 days')
                GROUP BY DATE(scrape_time), source_type
                ORDER BY date DESC, source_type
            ''')
            recent_stats = cursor.fetchall()
            
            return {
                'total': total,
                'source_stats': source_stats,
                'notified': notified,
                'unnotified': unnotified,
                'with_coordinates': with_coords,
                'coords_by_source': coords_by_source,
                'total_coordinate_points': total_coord_points,
                'bureau_stats': bureau_stats,
                'keyword_stats': keyword_stats,
                'recent_stats': recent_stats
            }
            
        except Exception as e:
            print(f"âŒ ç²å–çµ±è¨ˆè³‡è¨Šæ™‚å‡ºéŒ¯: {e}")
            import traceback
            traceback.print_exc()
            return None
        finally:
            conn.close()
    
    def print_statistics(self):
        """åˆ—å°çµ±è¨ˆè³‡è¨Šï¼ˆå¤šæºç‰ˆæœ¬ï¼‰"""
        stats = self.get_statistics()
        
        if stats:
            print("\n" + "=" * 60)
            print("ğŸ“Š å¤šæºæµ·äº‹è­¦å‘Šè³‡æ–™åº«çµ±è¨ˆ")
            print("=" * 60)
            print(f"ç¸½è­¦å‘Šæ•¸: {stats['total']}")
            
            # å„ä¾†æºçµ±è¨ˆ
            if stats['source_stats']:
                print("\nå„ä¾†æºçµ±è¨ˆ:")
                for source_type, source_country, count in stats['source_stats']:
                    flag = "ğŸ‡¹ğŸ‡¼" if source_country == "TW" else "ğŸ‡¨ğŸ‡³"
                    source_name = "å°ç£èˆªæ¸¯å±€" if source_type == "TW_MPB" else "ä¸­åœ‹æµ·äº‹å±€"
                    print(f"  {flag} {source_name}: {count} ç­†")
            
            print(f"\né€šçŸ¥ç‹€æ…‹:")
            print(f"  å·²é€šçŸ¥: {stats['notified']}")
            print(f"  æœªé€šçŸ¥: {stats['unnotified']}")
            
            if stats['total'] > 0:
                coord_percentage = stats['with_coordinates'] / stats['total'] * 100
                print(f"\nåº§æ¨™è³‡è¨Š:")
                print(f"  å«åº§æ¨™: {stats['with_coordinates']} ({coord_percentage:.1f}%)")
                print(f"  ç¸½åº§æ¨™é»æ•¸: {stats['total_coordinate_points']}")
                
                # å„ä¾†æºåº§æ¨™çµ±è¨ˆ
                if stats['coords_by_source']:
                    print("  å„ä¾†æºå«åº§æ¨™çµ±è¨ˆ:")
                    for source_type, count in stats['coords_by_source']:
                        flag = "ğŸ‡¹ğŸ‡¼" if source_type == "TW_MPB" else "ğŸ‡¨ğŸ‡³"
                        source_name = "å°ç£èˆªæ¸¯å±€" if source_type == "TW_MPB" else "ä¸­åœ‹æµ·äº‹å±€"
                        print(f"    {flag} {source_name}: {count} ç­†")
            
            if stats['recent_stats']:
                print("\næœ€è¿‘7å¤©æ–°å¢ (æŒ‰ä¾†æº):")
                current_date = None
                for date, source_type, count in stats['recent_stats']:
                    if date != current_date:
                        print(f"  {date}:")
                        current_date = date
                    flag = "ğŸ‡¹ğŸ‡¼" if source_type == "TW_MPB" else "ğŸ‡¨ğŸ‡³"
                    source_name = "å°ç£èˆªæ¸¯å±€" if source_type == "TW_MPB" else "ä¸­åœ‹æµ·äº‹å±€"
                    print(f"    {flag} {source_name}: {count} ç­†")
            
            if stats['bureau_stats']:
                print("\nå„ç™¼å¸ƒå–®ä½è­¦å‘Šæ•¸ (å‰10å):")
                cn_bureaus = [(b, c) for s, b, c in stats['bureau_stats'] if s == 'CN_MSA'][:5]
                tw_bureaus = [(b, c) for s, b, c in stats['bureau_stats'] if s == 'TW_MPB'][:5]
                
                if cn_bureaus:
                    print("  ğŸ‡¨ğŸ‡³ ä¸­åœ‹æµ·äº‹å±€:")
                    for bureau, count in cn_bureaus:
                        print(f"    {bureau}: {count}")
                
                if tw_bureaus:
                    print("  ğŸ‡¹ğŸ‡¼ å°ç£èˆªæ¸¯å±€:")
                    for bureau, count in tw_bureaus:
                        print(f"    {bureau}: {count}")
            
            if stats['keyword_stats']:
                print("\né—œéµå­—åŒ¹é…çµ±è¨ˆ (å‰10å):")
                for keyword, count in stats['keyword_stats'][:10]:
                    print(f"  {keyword}: {count}")
            
            print("=" * 60)
    
    def cleanup_old_records(self, days=30, source_type=None):
        """
        æ¸…ç†è¶…éæŒ‡å®šå¤©æ•¸çš„èˆŠè¨˜éŒ„
        source_type: None (å…¨éƒ¨), 'CN_MSA', 'TW_MPB'
        """
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        try:
            if source_type:
                cursor.execute('''
                    DELETE FROM warnings
                    WHERE scrape_time < datetime('now', '-' || ? || ' days')
                    AND source_type = ?
                ''', (days, source_type))
                source_desc = "å°ç£èˆªæ¸¯å±€" if source_type == "TW_MPB" else "ä¸­åœ‹æµ·äº‹å±€"
            else:
                cursor.execute('''
                    DELETE FROM warnings
                    WHERE scrape_time < datetime('now', '-' || ? || ' days')
                ''', (days,))
                source_desc = "å…¨éƒ¨ä¾†æº"
            
            deleted_count = cursor.rowcount
            conn.commit()
            
            print(f"âœ… å·²æ¸…ç† {source_desc} {deleted_count} ç­†è¶…é {days} å¤©çš„èˆŠè¨˜éŒ„")
            return deleted_count
            
        except Exception as e:
            print(f"âŒ æ¸…ç†èˆŠè¨˜éŒ„æ™‚å‡ºéŒ¯: {e}")
            return 0
        finally:
            conn.close()
    
    def backup_database(self, backup_path=None):
        """å‚™ä»½è³‡æ–™åº«"""
        if backup_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_path = f'backup_{self.db_name}_{timestamp}'
        
        try:
            import shutil
            shutil.copy2(self.db_name, backup_path)
            print(f"âœ… è³‡æ–™åº«å·²å‚™ä»½è‡³: {backup_path}")
            return True
        except Exception as e:
            print(f"âŒ å‚™ä»½å¤±æ•—: {e}")
            return False
    
    def get_source_summary(self):
        """ç²å–å„ä¾†æºæ‘˜è¦è³‡è¨Š"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                SELECT 
                    source_type,
                    source_country,
                    COUNT(*) as total_count,
                    SUM(CASE WHEN is_notified = 1 THEN 1 ELSE 0 END) as notified_count,
                    SUM(CASE WHEN is_notified = 0 THEN 1 ELSE 0 END) as unnotified_count,
                    SUM(CASE WHEN coordinates IS NOT NULL AND coordinates != '' AND coordinates != '[]' THEN 1 ELSE 0 END) as with_coords_count,
                    MAX(scrape_time) as latest_scrape
                FROM warnings
                GROUP BY source_type, source_country
                ORDER BY total_count DESC
            ''')
            
            results = cursor.fetchall()
            
            summary = {}
            for row in results:
                source_type, source_country, total, notified, unnotified, with_coords, latest = row
                
                summary[source_type] = {
                    'country': source_country,
                    'total': total,
                    'notified': notified,
                    'unnotified': unnotified,
                    'with_coordinates': with_coords,
                    'latest_scrape': latest,
                    'flag': "ğŸ‡¹ğŸ‡¼" if source_country == "TW" else "ğŸ‡¨ğŸ‡³",
                    'name': "å°ç£èˆªæ¸¯å±€" if source_type == "TW_MPB" else "ä¸­åœ‹æµ·äº‹å±€"
                }
            
            return summary
            
        except Exception as e:
            print(f"âŒ ç²å–ä¾†æºæ‘˜è¦æ™‚å‡ºéŒ¯: {e}")
            return {}
        finally:
            conn.close()
    
    def close(self):
        """é—œé–‰è³‡æ–™åº«é€£ç·šï¼ˆSQLite ä¸éœ€è¦ï¼Œä½†ä¿ç•™ä»‹é¢ä¸€è‡´æ€§ï¼‰"""
        pass


if __name__ == "__main__":
    # æ¸¬è©¦å¤šæºè³‡æ–™åº«ç®¡ç†åŠŸèƒ½
    try:
        print("ğŸ§ª æ¸¬è©¦å¤šæº SQLite è³‡æ–™åº«ç®¡ç†åŠŸèƒ½")
        print("=" * 60)
        
        db = DatabaseManager()
        
        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        db.print_statistics()
        
        # é¡¯ç¤ºå„ä¾†æºæ‘˜è¦
        summary = db.get_source_summary()
        if summary:
            print(f"\nğŸ“‹ å„ä¾†æºæ‘˜è¦:")
            for source_type, info in summary.items():
                print(f"  {info['flag']} {info['name']}: {info['total']} ç­† (æœªé€šçŸ¥: {info['unnotified']})")
        
        # é¡¯ç¤ºæœªé€šçŸ¥çš„è­¦å‘Š
        unnotified_cn = db.get_unnotified_warnings('CN_MSA')
        unnotified_tw = db.get_unnotified_warnings('TW_MPB')
        print(f"\nğŸ‡¨ğŸ‡³ ä¸­åœ‹æµ·äº‹å±€æœªé€šçŸ¥: {len(unnotified_cn)} ç­†")
        print(f"ğŸ‡¹ğŸ‡¼ å°ç£èˆªæ¸¯å±€æœªé€šçŸ¥: {len(unnotified_tw)} ç­†")
        
        # é¡¯ç¤ºå«åº§æ¨™çš„è­¦å‘Š
        with_coords_cn = db.get_warnings_with_coordinates('CN_MSA')
        with_coords_tw = db.get_warnings_with_coordinates('TW_MPB')
        print(f"\nğŸ‡¨ğŸ‡³ ä¸­åœ‹æµ·äº‹å±€å«åº§æ¨™: {len(with_coords_cn)} ç­†")
        print(f"ğŸ‡¹ğŸ‡¼ å°ç£èˆªæ¸¯å±€å«åº§æ¨™: {len(with_coords_tw)} ç­†")
        
        print("\n" + "=" * 60)
        print("âœ… å¤šæºè³‡æ–™åº«æ¸¬è©¦å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
