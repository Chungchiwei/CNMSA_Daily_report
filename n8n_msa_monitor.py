#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MSA èˆªè¡Œè­¦å‘Šç›£æ§ç³»çµ± - SQLite ç‰ˆæœ¬ï¼ˆå«åº§æ¨™æå–ï¼‰
ç‰ˆæœ¬: 2.1 (GitHub Actions å„ªåŒ–ç‰ˆ)
æ›´æ–°æ—¥æœŸ: 2026-01-07
åŠŸèƒ½: ä¸­åœ‹æµ·äº‹å±€ + å°ç£èˆªæ¸¯å±€é›™æºç›£æ§
"""

import platform
import subprocess
import os
import sys
import logging
import warnings
import json
import smtplib
import requests
import traceback
import re
import time
from datetime import datetime, timezone, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.image import MIMEImage
from dotenv import load_dotenv
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager
from database_manager import DatabaseManager
from keyword_manager import KeywordManager

# ==================== å¥—ä»¶æª¢æŸ¥èˆ‡è¼‰å…¥ ====================
try:
    from bs4 import BeautifulSoup
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    BS4_AVAILABLE = True
    print("âœ… BeautifulSoup4 è¼‰å…¥æˆåŠŸ")
except ImportError:
    BS4_AVAILABLE = False
    print("âš ï¸ BeautifulSoup4 æœªå®‰è£ï¼Œå°ç£èˆªæ¸¯å±€åŠŸèƒ½å°‡è¢«åœç”¨")
    
try:
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    import cartopy.crs as ccrs
    import cartopy.feature as cfeature
    from matplotlib.patches import Polygon
    MAPPING_AVAILABLE = True
    print("âœ… åœ°åœ–ç¹ªè£½æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
except ImportError as e:
    MAPPING_AVAILABLE = False
    print(f"âš ï¸ åœ°åœ–ç¹ªè£½æ¨¡çµ„æœªå®‰è£ï¼Œå°‡è·³éåœ°åœ–ç”Ÿæˆ")

# ==================== ç’°å¢ƒè¨­å®š ====================
os.environ['WDM_SSL_VERIFY'] = '0'
os.environ['WDM_LOG_LEVEL'] = '0'
load_dotenv()

warnings.filterwarnings('ignore')
logging.getLogger('selenium').setLevel(logging.ERROR)
logging.getLogger('urllib3').setLevel(logging.ERROR)
logging.getLogger('WDM').setLevel(logging.ERROR)

# Windows éŒ¯èª¤è¨Šæ¯éæ¿¾
if os.name == 'nt':
    class ErrorFilter:
        def __init__(self, stream):
            self.stream = stream
        def write(self, text):
            if any(k in text for k in ['ERROR:net', 'handshake failed', 'DEPRECATED_ENDPOINT']): 
                return
            self.stream.write(text)
        def flush(self): 
            self.stream.flush()
    sys.stderr = ErrorFilter(sys.stderr)


# ==================== ç¶“ç·¯åº¦æå–å™¨ ====================
class CoordinateExtractor:
    """æå–æ–‡æœ¬ä¸­çš„ç¶“ç·¯åº¦åº§æ¨™ï¼ˆæ”¯æ´å¤šç¨®æ ¼å¼ï¼‰"""
    
    def __init__(self):
        self.patterns = [
            r'(\d{1,3})-(\d{1,2}\.?\d*)\s*([NSnsåŒ—å—])\s+(\d{1,3})-(\d{1,2}\.?\d*)\s*([EWewæ±è¥¿])',
            r'(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?\s*([NSnsåŒ—å—])\s+(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?\s*([EWewæ±è¥¿])',
            r'(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?\s*([NSnsåŒ—å—])\s*[,ï¼Œ]\s*(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?\s*([EWewæ±è¥¿])',
        ]
        self.tw_pattern = r'([åŒ—å—]ç·¯)\s*(\d{1,3})\s*[åº¦\s]\s*(\d{1,2}(?:\.\d+)?)\s*[åˆ†\s]?.*?([æ±è¥¿]ç¶“)\s*(\d{1,3})\s*[åº¦\s]\s*(\d{1,2}(?:\.\d+)?)\s*[åˆ†\s]?'

    def extract_coordinates(self, text):
        if not text:
            return []
        
        coordinates = []
        clean_text = text.replace('ã€', ' ').replace('ï¼Œ', ' ').replace('ã€‚', ' ')
        clean_text = re.sub(r'\s+', ' ', clean_text)
        
        tw_matches = re.finditer(self.tw_pattern, clean_text)
        for match in tw_matches:
            try:
                coord = self._parse_tw_match(match)
                if coord and self._validate_coordinate(coord):
                    coordinates.append(coord)
            except:
                continue

        for pattern in self.patterns:
            matches = re.finditer(pattern, clean_text, re.IGNORECASE)
            for match in matches:
                try:
                    coord = self._parse_match(match)
                    if coord and self._validate_coordinate(coord):
                        coordinates.append(coord)
                except:
                    continue
        
        unique_coords = []
        for coord in coordinates:
            is_duplicate = False
            for existing in unique_coords:
                if abs(coord[0] - existing[0]) < 0.001 and abs(coord[1] - existing[1]) < 0.001:
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_coords.append(coord)
        
        return unique_coords
    
    def _parse_tw_match(self, match):
        try:
            groups = match.groups()
            if len(groups) < 6:
                return None
            
            lat_dir = groups[0]
            lat_deg = float(groups[1])
            lat_min = float(groups[2])
            lon_dir = groups[3]
            lon_deg = float(groups[4])
            lon_min = float(groups[5])
            
            lat = lat_deg + lat_min / 60
            lon = lon_deg + lon_min / 60
            
            if 'å—' in lat_dir:
                lat = -lat
            if 'è¥¿' in lon_dir:
                lon = -lon
                
            return (lat, lon)
        except:
            return None

    def _parse_match(self, match):
        try:
            groups = match.groups()
            if len(groups) < 6:
                return None
            
            lat_deg = float(groups[0])
            lat_min = float(groups[1]) if groups[1] else 0
            lat_dir = groups[2].upper()
            lon_deg = float(groups[3])
            lon_min = float(groups[4]) if groups[4] else 0
            lon_dir = groups[5].upper()
            
            lat = lat_deg + lat_min / 60
            lon = lon_deg + lon_min / 60
            
            if lat_dir in ['S', 's', 'å—']:
                lat = -lat
            if lon_dir in ['W', 'w', 'è¥¿']:
                lon = -lon
            
            return (lat, lon)
        except:
            return None
    
    def _validate_coordinate(self, coord):
        if not coord or len(coord) != 2:
            return False
        
        lat, lon = coord
        
        if not (-90 <= lat <= 90):
            return False
        if not (-180 <= lon <= 180):
            return False
        if abs(lat) < 0.01 and abs(lon) < 0.01:
            return False
        
        return True


# ==================== å°ç£èˆªæ¸¯å±€çˆ¬èŸ² ====================
class TWMaritimeNoticesCrawler:
    """å°ç£äº¤é€šéƒ¨èˆªæ¸¯å±€èˆªè¡Œè­¦å‘Šçˆ¬èŸ²"""
    
    def __init__(self, days=3):
        if not BS4_AVAILABLE:
            raise ImportError("BeautifulSoup4 æœªå®‰è£")
        
        self.base_url = "https://www.motcmpb.gov.tw/Information/Notice"
        self.params = {'SiteId': '1', 'NodeId': '483'}
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
        }
        self.days = days
        self.cutoff_date = datetime.now() - timedelta(days=days)
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def parse_date(self, date_string):
        if not date_string:
            return None
        
        try:
            date_string = date_string.strip()
            
            roc_patterns = [
                r'(\d{2,3})\s*[/-]\s*(\d{1,2})\s*[/-]\s*(\d{1,2})',
                r'(\d{2,3})\s*å¹´\s*(\d{1,2})\s*æœˆ\s*(\d{1,2})\s*æ—¥?'
            ]
            
            for pattern in roc_patterns:
                match = re.search(pattern, date_string)
                if match:
                    year = int(match.group(1)) + 1911
                    month = int(match.group(2))
                    day = int(match.group(3))
                    return datetime(year, month, day)
            
            for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%Y.%m.%d', '%Yå¹´%mæœˆ%dæ—¥']:
                try:
                    return datetime.strptime(date_string, fmt)
                except ValueError:
                    continue
            
            return None
        except:
            return None
    
    def is_within_date_range(self, date_string):
        if not date_string:
            return True
        parsed_date = self.parse_date(date_string)
        if parsed_date:
            return parsed_date >= self.cutoff_date
        return True
    
    def get_notices(self, page=1):
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                params = self.params.copy()
                if page > 1:
                    params['page'] = page
                
                print(f"  ğŸ“„ æ­£åœ¨è«‹æ±‚ç¬¬ {page} é  (å˜—è©¦ {attempt + 1}/{max_retries})...")
                
                response = self.session.get(self.base_url, params=params, timeout=30, verify=False)
                response.raise_for_status()
                response.encoding = 'utf-8'
                
                soup = BeautifulSoup(response.text, 'html.parser')
                notices = []
                
                contents_div = soup.find('div', class_='contents') or soup.find('div', id='container')
                
                if not contents_div:
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                    return []
                
                dl_list = contents_div.find_all('dl')
                
                if len(dl_list) <= 1:
                    return []
                
                for dl in dl_list[1:]:
                    try:
                        dt_list = dl.find_all('dt')
                        dd = dl.find('dd')
                        
                        if len(dt_list) < 2 or not dd:
                            continue
                        
                        number = dt_list[0].get_text(strip=True)
                        date = dt_list[1].get_text(strip=True)
                        unit = dt_list[2].get_text(strip=True) if len(dt_list) > 2 else 'èˆªæ¸¯å±€'
                        
                        if not self.is_within_date_range(date):
                            continue
                        
                        link_tag = dd.find('a')
                        if link_tag:
                            title = link_tag.get_text(strip=True)
                            link = link_tag.get('href', '')
                            if link and not link.startswith('http'):
                                link = f"https://www.motcmpb.gov.tw{link}"
                        else:
                            title = dd.get_text(strip=True)
                            link = ''
                        
                        notices.append({
                            'number': number,
                            'date': date,
                            'title': title,
                            'unit': unit,
                            'link': link
                        })
                        
                        print(f"    âœ… æ‰¾åˆ°: {number} - {title[:30]}...")
                        
                    except:
                        continue
                
                return notices
                
            except requests.exceptions.RequestException as e:
                print(f"    âš ï¸ è«‹æ±‚å¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries}): {str(e)[:100]}")
                if attempt < max_retries - 1:
                    time.sleep(3)
                    continue
                return []
            except Exception as e:
                print(f"    âŒ è§£æå¤±æ•—: {str(e)[:100]}")
                return []
        
        return []
    
    def crawl_recent_notices(self, max_pages=5):
        all_notices = []
        
        for page in range(1, max_pages + 1):
            notices = self.get_notices(page)
            
            if not notices:
                break
            
            dates = [self.parse_date(n.get('date', '')) for n in notices]
            valid_dates = [d for d in dates if d is not None]
            
            if valid_dates and min(valid_dates) < self.cutoff_date:
                break
            
            all_notices.extend(notices)
            
            if page < max_pages:
                time.sleep(2)
        
        return all_notices


# ==================== æµ·åœ–ç¹ªè£½å™¨ ====================
class MaritimeMapPlotter:
    """ç¹ªè£½æµ·äº‹è­¦å‘Šå€åŸŸåœ°åœ–"""
    
    def __init__(self):
        self.output_dir = "maps"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        self.chinese_font = self._setup_chinese_font()
    
    def _setup_chinese_font(self):
        try:
            import matplotlib.font_manager as fm
            
            font_paths = [
                'C:/Windows/Fonts/msyh.ttc',
                '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
                '/System/Library/Fonts/PingFang.ttc',
            ]
            
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        return fm.FontProperties(fname=font_path)
                    except:
                        continue
            
            return None
        except:
            return None
    
    def plot_warnings(self, warnings_data, output_filename="maritime_warnings.png"):
        if not MAPPING_AVAILABLE:
            return None
        
        if not warnings_data:
            return None
        
        try:
            all_coords = []
            for warning in warnings_data:
                coords = warning.get('coordinates', [])
                if coords:
                    all_coords.extend(coords)
            
            if not all_coords:
                return None
            
            lats = [c[0] for c in all_coords]
            lons = [c[1] for c in all_coords]
            
            lat_range = max(lats) - min(lats)
            lon_range = max(lons) - min(lons)
            
            lat_margin = max(lat_range * 0.1, 1)
            lon_margin = max(lon_range * 0.1, 1)
            
            lat_min = min(lats) - lat_margin
            lat_max = max(lats) + lat_margin
            lon_min = min(lons) - lon_margin
            lon_max = max(lons) + lon_margin
            
            fig = plt.figure(figsize=(18, 14), dpi=150)
            ax = plt.axes(projection=ccrs.PlateCarree())
            
            ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())
            
            ax.add_feature(cfeature.LAND, facecolor='#f5f5dc', edgecolor='#8b7355', linewidth=1)
            ax.add_feature(cfeature.OCEAN, facecolor='#e0f2ff')
            ax.add_feature(cfeature.COASTLINE, linewidth=1.5, edgecolor='#2c5f7a')
            ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=1, edgecolor='#666666')
            
            gl = ax.gridlines(draw_labels=True, linewidth=0.8, color='gray', alpha=0.5, linestyle='--')
            gl.top_labels = False
            gl.right_labels = False
            
            colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6', '#e67e22']
            plotted_bureaus = set()
            
            for idx, warning in enumerate(warnings_data):
                coords = warning.get('coordinates', [])
                if not coords:
                    continue
                
                color = colors[idx % len(colors)]
                bureau = warning.get('bureau', 'Unknown')
                
                for lat, lon in coords:
                    label = bureau if bureau not in plotted_bureaus else ""
                    if label:
                        plotted_bureaus.add(bureau)
                    
                    ax.plot(lon, lat, marker='o', color=color, markersize=14, 
                           markeredgecolor='white', markeredgewidth=2.5,
                           transform=ccrs.PlateCarree(), label=label, zorder=5)
                
                if len(coords) > 1:
                    lons_line = [c[1] for c in coords] + [coords[0][1]]
                    lats_line = [c[0] for c in coords] + [coords[0][0]]
                    ax.plot(lons_line, lats_line, color=color, linewidth=3, 
                           linestyle='--', alpha=0.8, transform=ccrs.PlateCarree(), zorder=4)
                    ax.fill(lons_line, lats_line, color=color, alpha=0.2, 
                           transform=ccrs.PlateCarree(), zorder=3)
            
            title_text = f"Maritime Navigation Warnings Map\n({len(warnings_data)} warnings, {len(all_coords)} coordinates)"
            plt.title(title_text, fontsize=20, fontweight='bold', pad=30)
            
            handles, labels = ax.get_legend_handles_labels()
            if handles:
                by_label = dict(zip(labels, handles))
                ax.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize=12)
            
            output_path = os.path.join(self.output_dir, output_filename)
            plt.tight_layout()
            plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
            plt.close()
            
            print(f"âœ… åœ°åœ–å·²å„²å­˜: {output_path}")
            return output_path
        
        except Exception as e:
            print(f"âŒ åœ°åœ–ç¹ªè£½å¤±æ•—: {e}")
            return None


# ==================== Teams é€šçŸ¥é¡åˆ¥ ====================
class TeamsNotifier:
    def __init__(self, webhook_url):
        self.webhook_url = webhook_url
    
    def _fix_url(self, url):
        if not url: 
            return "#"
        url = url.strip()
        if url.startswith(('http://', 'https://')): 
            return url
        if url.startswith(('javascript:', '#')): 
            return "#"
        if url.startswith('/'):
            if 'motcmpb' in url or '/Information' in url:
                return f"https://www.motcmpb.gov.tw{url}"
            else:
                return f"https://www.msa.gov.cn{url}"
        return url
    
    def _create_adaptive_card(self, title, body_elements, actions=None):
        card_content = {
            "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
            "type": "AdaptiveCard",
            "version": "1.4",
            "body": [{"type": "TextBlock", "text": title, "weight": "Bolder", "size": "Large", "color": "Attention"}] + body_elements
        }
        if actions:
            card_content["actions"] = actions
        return {"type": "message", "attachments": [{"contentType": "application/vnd.microsoft.card.adaptive", "contentUrl": None, "content": card_content}]}

    def send_warning_notification(self, warning_data):
        if not self.webhook_url: 
            return False
        
        try:
            warning_id, bureau, title, link, pub_time, keywords, scrape_time, coordinates = warning_data
            fixed_link = self._fix_url(link)
            
            coord_text = "ç„¡åº§æ¨™è³‡è¨Š"
            if coordinates:
                try:
                    coord_list = json.loads(coordinates) if isinstance(coordinates, str) else coordinates
                    if coord_list:
                        coord_text = "\n".join([f"â€¢ ({c[0]:.4f}Â°, {c[1]:.4f}Â°)" for c in coord_list[:5]])
                        if len(coord_list) > 5:
                            coord_text += f"\nâ€¢ ...é‚„æœ‰ {len(coord_list)-5} å€‹åº§æ¨™"
                except:
                    coord_text = "åº§æ¨™æ ¼å¼éŒ¯èª¤"
            
            body = [
                {"type": "FactSet", "facts": [
                    {"title": "ğŸ¢ ç™¼å¸ƒå–®ä½:", "value": bureau},
                    {"title": "ğŸ“‹ æ¨™é¡Œ:", "value": title},
                    {"title": "ğŸ“… ç™¼å¸ƒæ™‚é–“:", "value": pub_time},
                    {"title": "ğŸ” é—œéµå­—:", "value": keywords},
                    {"title": "ğŸ“ åº§æ¨™:", "value": coord_text}
                ]},
                {"type": "TextBlock", "text": f"ğŸ”— {fixed_link}", "wrap": True, "size": "Small"}
            ]
            
            actions = [{"type": "Action.OpenUrl", "title": "ğŸŒ é–‹å•Ÿå…¬å‘Š", "url": fixed_link}]
            payload = self._create_adaptive_card("ğŸš¨ èˆªè¡Œè­¦å‘Šé€šçŸ¥", body, actions)
            
            response = requests.post(self.webhook_url, json=payload, headers={"Content-Type": "application/json"}, timeout=30)
            
            if response.status_code in [200, 202]:
                print(f"  âœ… Teams é€šçŸ¥ç™¼é€æˆåŠŸ (ID: {warning_id})")
                return True
            else:
                print(f"  âŒ Teams é€šçŸ¥å¤±æ•—: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Teams å–®ç™¼å¤±æ•—: {e}")
            return False

    def send_batch_notification(self, warnings_list):
        if not self.webhook_url or not warnings_list: 
            return False
        
        try:
            body_elements = [{"type": "TextBlock", "text": f"ç™¼ç¾ **{len(warnings_list)}** å€‹æ–°çš„èˆªè¡Œè­¦å‘Š", "size": "Medium", "weight": "Bolder"}]
            actions = []
            
            for idx, w in enumerate(warnings_list[:8], 1):
                _, bureau, title, link, pub_time, _, _, coordinates = w
                fixed_link = self._fix_url(link)
                
                coord_summary = "ç„¡åº§æ¨™"
                if coordinates:
                    try:
                        coord_list = json.loads(coordinates) if isinstance(coordinates, str) else coordinates
                        if coord_list:
                            coord_summary = f"{len(coord_list)} å€‹åº§æ¨™é»"
                    except:
                        pass
                
                body_elements.extend([
                    {"type": "TextBlock", "text": f"**{idx}. {bureau}**", "weight": "Bolder", "spacing": "Medium"},
                    {"type": "TextBlock", "text": title[:100], "wrap": True},
                    {"type": "TextBlock", "text": f"ğŸ“… {pub_time} | ğŸ“ {coord_summary}", "size": "Small", "isSubtle": True}
                ])
                
                if len(actions) < 4:
                    actions.append({"type": "Action.OpenUrl", "title": f"ğŸ“„ å…¬å‘Š {idx}", "url": fixed_link})

            if len(warnings_list) > 8:
                body_elements.append({"type": "TextBlock", "text": f"*...é‚„æœ‰ {len(warnings_list)-8} ç­†æœªé¡¯ç¤º*", "isSubtle": True})
            
            payload = self._create_adaptive_card(f"ğŸš¨ æ‰¹é‡è­¦å‘Šé€šçŸ¥ ({len(warnings_list)})", body_elements, actions)
            response = requests.post(self.webhook_url, json=payload, headers={"Content-Type": "application/json"}, timeout=30)
            
            if response.status_code in [200, 202]:
                print(f"âœ… Teams æ‰¹é‡é€šçŸ¥ç™¼é€æˆåŠŸ ({len(warnings_list)} ç­†)")
                return True
            else:
                print(f"âŒ Teams æ‰¹é‡é€šçŸ¥å¤±æ•—: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Teams æ‰¹é‡ç™¼é€å¤±æ•—: {e}")
            return False


# ==================== Gmail ç™¼ä¿¡é¡åˆ¥ ====================
class GmailRelayNotifier:
    def __init__(self, user, password, target_email):
        self.user = user
        self.password = password
        self.target = target_email

    def send_trigger_email(self, report_data: dict, report_html: str, map_path: str = None) -> bool:
        if not self.user or not self.password or not self.target: 
            print("âš ï¸ Email è¨­å®šä¸å®Œæ•´")
            return False
        
        msg = MIMEMultipart('related')
        msg['From'] = self.user
        msg['To'] = self.target
        msg['Subject'] = "GITHUB_TRIGGER_CN_MSA_REPORT"
        
        msg_alternative = MIMEMultipart('alternative')
        msg.attach(msg_alternative)
        
        text_part = MIMEText(json.dumps(report_data, ensure_ascii=False, indent=2), 'plain', 'utf-8')
        msg_alternative.attach(text_part)
        
        html_part = MIMEText(report_html, 'html', 'utf-8')
        msg_alternative.attach(html_part)
        
        if map_path and os.path.exists(map_path):
            try:
                with open(map_path, 'rb') as f:
                    img_data = f.read()
                    img = MIMEImage(img_data)
                    img.add_header('Content-ID', '<map_image>')
                    img.add_header('Content-Disposition', 'inline', filename='maritime_warnings_map.png')
                    msg.attach(img)
                print("  âœ… åœ°åœ–å·²åµŒå…¥ Email")
            except Exception as e:
                print(f"  âš ï¸ ç„¡æ³•åµŒå…¥åœ°åœ–: {e}")

        try:
            print(f"ğŸ“§ ç™¼é€ Email çµ¦ {self.target}...")
            server = smtplib.SMTP("smtp.gmail.com", 587, timeout=30)
            server.starttls()
            server.login(self.user, self.password)
            server.sendmail(self.user, self.target, msg.as_string())
            server.quit()
            print("âœ… Email ç™¼é€æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ Email ç™¼é€å¤±æ•—: {e}")
            return False


# ==================== ä¸»çˆ¬èŸ²é¡åˆ¥ (GitHub Actions å„ªåŒ–ç‰ˆ) ====================
class MSANavigationWarningsScraper:
    def __init__(self, webhook_url=None, enable_teams=True, send_mode='batch', headless=True, 
                 mail_user=None, mail_pass=None, target_email=None, enable_tw=True):
        print("ğŸš€ åˆå§‹åŒ–æµ·äº‹å±€çˆ¬èŸ²...")
        
        self.keyword_manager = KeywordManager()
        self.keywords = self.keyword_manager.get_keywords()
        print(f"ğŸ“‹ è¼‰å…¥ {len(self.keywords)} å€‹ç›£æ§é—œéµå­—")
        
        self.db_manager = DatabaseManager()
        self.coord_extractor = CoordinateExtractor()
        self.map_plotter = MaritimeMapPlotter() if MAPPING_AVAILABLE else None
        
        self.enable_teams = enable_teams and webhook_url
        self.send_mode = send_mode
        self.teams_notifier = TeamsNotifier(webhook_url) if self.enable_teams else None
        self.email_notifier = GmailRelayNotifier(mail_user, mail_pass, target_email)
        
        self.enable_tw = enable_tw and BS4_AVAILABLE
        if self.enable_tw:
            try:
                self.tw_crawler = TWMaritimeNoticesCrawler(days=3)
                print("âœ… å°ç£èˆªæ¸¯å±€çˆ¬èŸ²å·²å•Ÿç”¨")
            except ImportError:
                print("âš ï¸ å°ç£èˆªæ¸¯å±€çˆ¬èŸ²å•Ÿç”¨å¤±æ•—")
                self.enable_tw = False
        
        if self.enable_teams:
            print(f"âœ… Teams é€šçŸ¥å·²å•Ÿç”¨ (æ¨¡å¼: {send_mode})")
        
        print("ğŸŒ æ­£åœ¨å•Ÿå‹• Chrome WebDriver...")
        
        options = webdriver.ChromeOptions()
        
        if headless:
            options.add_argument('--headless=new')
        
        # GitHub Actions å„ªåŒ–åƒæ•¸
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-software-rasterizer')
        options.add_argument('--disable-background-networking')
        options.add_argument('--disable-background-timer-throttling')
        options.add_argument('--disable-backgrounding-occluded-windows')
        options.add_argument('--disable-breakpad')
        options.add_argument('--disable-component-extensions-with-background-pages')
        options.add_argument('--disable-features=TranslateUI')
        options.add_argument('--disable-ipc-flooding-protection')
        options.add_argument('--disable-renderer-backgrounding')
        options.add_argument('--enable-features=NetworkService,NetworkServiceInProcess')
        options.add_argument('--force-color-profile=srgb')
        options.add_argument('--metrics-recording-only')
        options.add_argument('--mute-audio')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # é é¢è¼‰å…¥ç­–ç•¥
        options.page_load_strategy = 'eager'
        
        prefs = {
            'profile.managed_default_content_settings.images': 2,
            'profile.default_content_setting_values.notifications': 2,
        }
        options.add_experimental_option('prefs', prefs)
        options.add_experimental_option('excludeSwitches', ['enable-logging', 'enable-automation'])
        options.add_experimental_option('useAutomationExtension', False)
        
        service = Service(ChromeDriverManager().install())
        
        try:
            self.driver = webdriver.Chrome(service=service, options=options)
            # GitHub Actions éœ€è¦æ›´é•·çš„è¶…æ™‚æ™‚é–“
            self.driver.set_page_load_timeout(180)
            self.driver.set_script_timeout(30)
            self.driver.implicitly_wait(10)
            self.wait = WebDriverWait(self.driver, 30)
            print("  âœ… WebDriver å•Ÿå‹•æˆåŠŸ")
        except Exception as e:
            print(f"âŒ WebDriver åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
        
        self.three_days_ago = datetime.now() - timedelta(days=3)
        self.new_warnings = []
        self.captured_warnings_data = []
        
        print("âœ… çˆ¬èŸ²åˆå§‹åŒ–å®Œæˆ\n")

    def check_keywords(self, text):
        if not text:
            return []
        return [k for k in self.keywords if k.lower() in text.lower()]

    def parse_date(self, date_str):
        if not date_str:
            return None
        for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%Yå¹´%mæœˆ%dæ—¥']:
            try: 
                return datetime.strptime(date_str.strip(), fmt)
            except: 
                continue
        return None

    def scrape_bureau_warnings(self, bureau_name, bureau_element):
        print(f"\nğŸ” æŠ“å–: {bureau_name}")
        try:
            self.driver.execute_script("arguments[0].scrollIntoView(true); arguments[0].click();", bureau_element)
            time.sleep(3)
            
            self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, "right_main")))
            
            print("  ğŸ“‹ æ­£åœ¨æ”¶é›†è­¦å‘Šåˆ—è¡¨...")
            items = self.driver.find_elements(By.CSS_SELECTOR, ".right_main a")
            
            warnings_to_process = []
            
            for idx, item in enumerate(items, 1):
                try:
                    title = item.get_attribute('title') or item.text.strip()
                    title = re.sub(r'\s*\d{4}-\d{2}-\d{2}\s*$', '', title)
                    if not title:
                        continue

                    matched = self.check_keywords(title)
                    if not matched:
                        continue

                    link = item.get_attribute('href') or ''
                    if link.startswith('/'):
                        link = f"https://www.msa.gov.cn{link}"
                    
                    if not link or link.startswith(('javascript:', '#')):
                        continue
                    
                    try:
                        publish_time = item.find_element(By.CSS_SELECTOR, ".time").text.strip()
                    except:
                        match = re.search(r'\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}', item.text)
                        publish_time = match.group() if match else ""

                    if publish_time:
                        p_date = self.parse_date(publish_time)
                        if p_date and p_date < self.three_days_ago:
                            continue
                    
                    title_coords = self.coord_extractor.extract_coordinates(title)
                    
                    warnings_to_process.append({
                        'title': title,
                        'link': link,
                        'publish_time': publish_time,
                        'keywords': matched,
                        'title_coords': title_coords
                    })
                    
                    print(f"  âœ… [{idx}] æ”¶é›†: {title[:40]}...")
                    
                except:
                    continue
            
            print(f"  ğŸ“Š å…±æ”¶é›†åˆ° {len(warnings_to_process)} å€‹å¾…è™•ç†è­¦å‘Š")
            
            for idx, warning in enumerate(warnings_to_process, 1):
                try:
                    print(f"\n  ğŸ“ [{idx}/{len(warnings_to_process)}] è™•ç†: {warning['title'][:40]}...")
                    
                    coordinates = list(warning['title_coords'])
                    
                    try:
                        print(f"    ğŸŒ è¨ªå•è©³ç´°é ...")
                        self.driver.get(warning['link'])
                        time.sleep(3)
                        
                        self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
                        
                        if len(self.driver.page_source) > 500:
                            try:
                                content_div = self.driver.find_element(By.CSS_SELECTOR, ".text#ch_p")
                                page_text = content_div.text
                            except:
                                page_text = self.driver.find_element(By.TAG_NAME, 'body').text
                            
                            if len(page_text) > 50:
                                page_coords = self.coord_extractor.extract_coordinates(page_text)
                                
                                if page_coords:
                                    for pc in page_coords:
                                        if pc not in coordinates:
                                            coordinates.append(pc)
                                    print(f"    âœ… å¾é é¢æå–åˆ° {len(page_coords)} å€‹åº§æ¨™")
                    
                    except Exception as e:
                        print(f"    âš ï¸ è¨ªå•è©³ç´°é å¤±æ•—: {str(e)[:100]}")
                    
                    if coordinates:
                        print(f"    ğŸ“ ç¸½å…±æå–åˆ° {len(coordinates)} å€‹åº§æ¨™")
                    
                    db_data = (
                        bureau_name,
                        warning['title'],
                        warning['link'],
                        warning['publish_time'],
                        ', '.join(warning['keywords']),
                        datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        coordinates
                    )
                    
                    is_new, w_id = self.db_manager.save_warning(db_data)
                    
                    if is_new and w_id:
                        self.new_warnings.append(w_id)
                        self.captured_warnings_data.append({
                            'id': w_id,
                            'bureau': bureau_name,
                            'title': warning['title'],
                            'link': warning['link'],
                            'time': warning['publish_time'],
                            'keywords': warning['keywords'],
                            'coordinates': coordinates
                        })
                        print(f"    âœ… æ–°è­¦å‘Šå·²å„²å­˜ (ID: {w_id})")
                        
                        if self.enable_teams and self.send_mode == 'individual':
                            if self.teams_notifier.send_warning_notification((w_id,) + db_data):
                                self.db_manager.mark_as_notified(w_id)
                            time.sleep(1)
                    else:
                        print(f"    â­ï¸ è­¦å‘Šå·²å­˜åœ¨")
                
                except Exception as e:
                    print(f"  âŒ è™•ç†è­¦å‘Š {idx} æ™‚å‡ºéŒ¯: {str(e)[:100]}")
                    continue
            
            print(f"\n  âœ… {bureau_name} è™•ç†å®Œæˆ")
            
            try:
                print(f"  ğŸ”™ è¿”å›èˆªè¡Œè­¦å‘Šåˆ—è¡¨é ...")
                self.driver.get('https://www.msa.gov.cn/page/outter/weather.jsp')
                time.sleep(3)
                
                nav_btn = self.wait.until(
                    EC.element_to_be_clickable((By.XPATH, "//span[contains(text(), 'èˆªè¡Œè­¦å‘Š')]"))
                )
                self.driver.execute_script("arguments[0].click();", nav_btn)
                time.sleep(2)
                
                print(f"  âœ… å·²è¿”å›åˆ—è¡¨é ")
            except Exception as e:
                print(f"  âš ï¸ è¿”å›åˆ—è¡¨é å¤±æ•—: {e}")
        
        except Exception as e:
            print(f"âŒ æŠ“å– {bureau_name} éŒ¯èª¤: {e}")

    def scrape_tw_maritime_notices(self):
        if not self.enable_tw:
            return
        
        print("\n" + "="*60)
        print("ğŸ‡¹ğŸ‡¼ é–‹å§‹çˆ¬å–å°ç£èˆªæ¸¯å±€èˆªè¡Œè­¦å‘Š")
        print("="*60)
        
        try:
            notices = self.tw_crawler.crawl_recent_notices(max_pages=5)
            
            if not notices:
                print("  âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å°ç£èˆªè¡Œè­¦å‘Š")
                return
            
            print(f"\n  ğŸ“Š å…±æ‰¾åˆ° {len(notices)} ç­†å°ç£èˆªè¡Œè­¦å‘Š")
            
            for idx, notice in enumerate(notices, 1):
                try:
                    title = notice.get('title', '')
                    link = notice.get('link', '')
                    date = notice.get('date', '')
                    unit = notice.get('unit', 'å°ç£èˆªæ¸¯å±€')
                    
                    matched = self.check_keywords(title)
                    if not matched:
                        continue
                    
                    print(f"\n  ğŸ“ [{idx}] è™•ç†: {title[:40]}...")
                    
                    coordinates = self.coord_extractor.extract_coordinates(title)
                    
                    if link and link.startswith('http'):
                        try:
                            response = requests.get(link, timeout=15, verify=False)
                            response.encoding = 'utf-8'
                            
                            if response.status_code == 200:
                                soup = BeautifulSoup(response.text, 'html.parser')
                                content_div = soup.find('div', id='content', class_='content')
                                
                                if content_div:
                                    content_text = content_div.get_text(separator=' ', strip=True)
                                    page_coords = self.coord_extractor.extract_coordinates(content_text)
                                    
                                    if page_coords:
                                        for pc in page_coords:
                                            if pc not in coordinates:
                                                coordinates.append(pc)
                        except:
                            pass
                    
                    if coordinates:
                        print(f"    ğŸ“ ç¸½å…±æå–åˆ° {len(coordinates)} å€‹åº§æ¨™")
                    
                    date_str = date.strftime('%Y-%m-%d') if isinstance(date, datetime) else str(date)

                    db_data = (
                        f"å°ç£-{unit}",
                        title,
                        link,
                        date_str,
                        ', '.join(matched),
                        datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        coordinates
                    )
                    
                    is_new, w_id = self.db_manager.save_warning(db_data)
                    
                    if is_new and w_id:
                        self.new_warnings.append(w_id)
                        self.captured_warnings_data.append({
                            'id': w_id,
                            'bureau': f"å°ç£-{unit}",
                            'title': title,
                            'link': link,
                            'time': date_str,
                            'keywords': matched,
                            'coordinates': coordinates
                        })
                        print(f"    âœ… æ–°è­¦å‘Šå·²å„²å­˜ (ID: {w_id})")
                        
                        if self.enable_teams and self.send_mode == 'individual':
                            if self.teams_notifier.send_warning_notification((w_id,) + db_data):
                                self.db_manager.mark_as_notified(w_id)
                            time.sleep(1)
                    else:
                        print(f"    â­ï¸ è­¦å‘Šå·²å­˜åœ¨")
                
                except Exception as e:
                    print(f"  âŒ è™•ç†è­¦å‘Š {idx} æ™‚å‡ºéŒ¯: {str(e)[:100]}")
                    continue
            
            print(f"\n  âœ… å°ç£èˆªæ¸¯å±€è™•ç†å®Œæˆ")
        
        except Exception as e:
            print(f"âŒ çˆ¬å–å°ç£èˆªæ¸¯å±€éŒ¯èª¤: {e}")

    def _generate_report(self, duration, map_path=None):
        count = len(self.captured_warnings_data)
        status_color = "#2E7D32" if count == 0 else "#D9534F"
        
        utc_now = datetime.now(timezone.utc)
        now_str_UTC = utc_now.strftime('%Y-%m-%d %H:%M')
        lt_now = utc_now + timedelta(hours=8)
        now_str_LT = lt_now.strftime('%Y-%m-%d %H:%M')
        
        total_coords = sum(len(w.get('coordinates', [])) for w in self.captured_warnings_data)
        
        html = f"""
        <html>
        <head><meta charset="UTF-8"><style>
        body{{font-family:Arial,sans-serif;margin:0;padding:0}}
        .header{{background:#003366;color:white;padding:20px}}
        .summary{{background:#f8f9fa;padding:15px}}
        table{{width:100%;border-collapse:collapse}}
        th,td{{padding:10px;text-align:left;border-bottom:1px solid #ddd}}
        th{{background:#005a8d;color:white}}
        </style></head>
        <body>
        <div class="header"><h2>ğŸš¢ æµ·äº‹èˆªè¡Œè­¦å‘Šç›£æ§å ±å‘Š</h2><div>ğŸ“… {now_str_LT} (TPE) | {now_str_UTC} (UTC)</div></div>
        <div class="summary"><strong style="color:{status_color}">ğŸ“Š æœ¬æ¬¡åŸ·è¡Œæ–°å¢ {count} å€‹è­¦å‘Š</strong><br>
        ğŸ“ å…±æå–åº§æ¨™é»: {total_coords} å€‹<br>â±ï¸ åŸ·è¡Œè€—æ™‚: {duration:.2f} ç§’</div>
        """
        
        if map_path and os.path.exists(map_path):
            html += '<div style="text-align:center;padding:15px"><h3>ğŸ—ºï¸ è­¦å‘Šå€åŸŸåˆ†ä½ˆåœ–</h3><img src="cid:map_image" style="max-width:100%"></div>'
        
        if count > 0:
            html += '<table><thead><tr><th>ç™¼å¸ƒå–®ä½</th><th>æ¨™é¡Œ</th><th>æ™‚é–“</th><th>åº§æ¨™</th></tr></thead><tbody>'
            for item in self.captured_warnings_data:
                coords = item.get('coordinates', [])
                coord_html = "ç„¡åº§æ¨™" if not coords else f"{len(coords)} å€‹åº§æ¨™é»"
                html += f'<tr><td>{item["bureau"]}</td><td><a href="{item["link"]}">{item["title"]}</a></td><td>{item["time"]}</td><td>{coord_html}</td></tr>'
            html += '</tbody></table>'
        else:
            html += '<div style="padding:30px;text-align:center">âœ… ç›®å‰æ²’æœ‰ç›£æ§åˆ°æ–°çš„èˆªè¡Œè­¦å‘Š</div>'
        
        html += '</body></html>'
        
        json_data = {
            "execution_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "duration": round(duration, 2),
            "new_warnings_count": count,
            "total_coordinates": total_coords,
            "new_warnings": self.captured_warnings_data
        }
        
        return json_data, html

    def run(self):
        """ä¸»åŸ·è¡Œæµç¨‹ (å«é‡è©¦æ©Ÿåˆ¶)"""
        start = datetime.now()
        map_path = None
        
        try:
            print(f"â±ï¸ é–‹å§‹åŸ·è¡Œ... (é€šçŸ¥æ¨¡å¼: {self.send_mode})")
            
            # ========== 1. ä¸­åœ‹æµ·äº‹å±€çˆ¬å– (å«é‡è©¦) ==========
            print("\n" + "="*60)
            print("ğŸ‡¨ğŸ‡³ é–‹å§‹çˆ¬å–ä¸­åœ‹æµ·äº‹å±€")
            print("="*60)
            
            max_retries = 3
            retry_delay = 10
            
            for attempt in range(max_retries):
                try:
                    print(f"ğŸŒ æ­£åœ¨è¼‰å…¥æµ·äº‹å±€ç¶²ç«™... (å˜—è©¦ {attempt + 1}/{max_retries})")
                    
                    try:
                        self.driver.get('https://www.msa.gov.cn/page/outter/weather.jsp')
                    except TimeoutException:
                        print("  âš ï¸ é é¢è¼‰å…¥è¶…æ™‚ï¼Œå˜—è©¦åœæ­¢è¼‰å…¥...")
                        self.driver.execute_script("window.stop();")
                    
                    time.sleep(5)
                    
                    if "èˆªè¡Œè­¦å‘Š" in self.driver.page_source or len(self.driver.page_source) > 1000:
                        print("  âœ… é é¢è¼‰å…¥æˆåŠŸ")
                        break
                    else:
                        raise Exception("é é¢å…§å®¹ä¸å®Œæ•´")
                    
                except Exception as e:
                    print(f"  âš ï¸ è¼‰å…¥å¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries}): {str(e)[:100]}")
                    
                    if attempt < max_retries - 1:
                        print(f"  â³ ç­‰å¾… {retry_delay} ç§’å¾Œé‡è©¦...")
                        time.sleep(retry_delay)
                        retry_delay += 10
                    else:
                        print("  âŒ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œè·³éä¸­åœ‹æµ·äº‹å±€")
                        raise
            
            print("ğŸ” å°‹æ‰¾ã€Œèˆªè¡Œè­¦å‘Šã€æŒ‰éˆ•...")
            
            try:
                nav_btn = self.wait.until(
                    EC.element_to_be_clickable((By.XPATH, "//span[contains(text(), 'èˆªè¡Œè­¦å‘Š')]"))
                )
                self.driver.execute_script("arguments[0].click();", nav_btn)
                time.sleep(3)
                print("âœ… å·²é»æ“Šã€Œèˆªè¡Œè­¦å‘Šã€")
            except TimeoutException:
                print("  âš ï¸ æ‰¾ä¸åˆ°ã€Œèˆªè¡Œè­¦å‘Šã€æŒ‰éˆ•")
                pass
            
            bureaus = [
                b.text.strip() 
                for b in self.driver.find_elements(By.CSS_SELECTOR, ".nav_lv2_list .nav_lv2_text") 
                if b.text.strip()
            ]
            
            print(f"ğŸ“ æ‰¾åˆ° {len(bureaus)} å€‹æµ·äº‹å±€")
            
            for b_name in bureaus:
                try:
                    elem = self.driver.find_element(
                        By.XPATH, 
                        f"//div[@class='nav_lv2_text' and contains(text(), '{b_name}')]"
                    )
                    self.scrape_bureau_warnings(b_name, elem)
                except Exception as e:
                    print(f"âš ï¸ è·³é {b_name}: {str(e)[:100]}")
                    continue
            
            print(f"\nâœ… ä¸­åœ‹æµ·äº‹å±€çˆ¬å–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ ä¸­åœ‹æµ·äº‹å±€çˆ¬å–å¤±æ•—: {e}")

        # ========== 2. å°ç£èˆªæ¸¯å±€çˆ¬å– ==========
        if self.enable_tw:
            self.scrape_tw_maritime_notices()
        
        # ========== 3. Teams é€šçŸ¥ ==========
        if self.send_mode == 'batch' and self.enable_teams and self.new_warnings:
            print(f"\nğŸ“¤ æº–å‚™ Teams æ‰¹é‡ç™¼é€...")
            unnotified = self.db_manager.get_unnotified_warnings()
            warnings_to_send = [w for w in unnotified if w[0] in self.new_warnings]
            
            if warnings_to_send:
                if self.teams_notifier.send_batch_notification(warnings_to_send):
                    for w_id in self.new_warnings: 
                        self.db_manager.mark_as_notified(w_id)
        
        # ========== 4. åœ°åœ– ==========
        if self.captured_warnings_data and self.map_plotter:
            print("\nğŸ—ºï¸ æ­£åœ¨ç¹ªè£½æµ·åœ–...")
            warnings_for_map = [
                {'title': w['title'], 'coordinates': w.get('coordinates', []), 'bureau': w['bureau']}
                for w in self.captured_warnings_data if w.get('coordinates')
            ]
            
            if warnings_for_map:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                map_path = self.map_plotter.plot_warnings(warnings_for_map, f"maritime_warnings_{timestamp}.png")
        
        # ========== 5. å ±å‘Š ==========
        duration = (datetime.now() - start).total_seconds()
        print(f"\n{'='*60}")
        print(f"âœ… åŸ·è¡Œå®Œæˆ")
        print(f"â±ï¸ è€—æ™‚: {duration:.2f} ç§’")
        print(f"ğŸ“Š æ–°è­¦å‘Š: {len(self.new_warnings)} ç­†")
        
        cn_count = sum(1 for w in self.captured_warnings_data if not w['bureau'].startswith('å°ç£'))
        tw_count = sum(1 for w in self.captured_warnings_data if w['bureau'].startswith('å°ç£'))
        print(f"   ğŸ‡¨ğŸ‡³ ä¸­åœ‹: {cn_count} ç­†")
        print(f"   ğŸ‡¹ğŸ‡¼ å°ç£: {tw_count} ç­†")
        
        if map_path:
            print(f"ğŸ—ºï¸ åœ°åœ–: {map_path}")
        print(f"{'='*60}\n")
        
        # ========== 6. Email ==========
        if self.new_warnings:
            print("ğŸ“§ æ­£åœ¨ç”Ÿæˆä¸¦ç™¼é€ Email å ±å‘Š...")
            j_data, h_data = self._generate_report(duration, map_path)
            self.email_notifier.send_trigger_email(j_data, h_data, map_path)
            
            print("ğŸ“Š æ­£åœ¨åŒ¯å‡º Excel...")
            self.db_manager.export_to_excel()
        else:
            print("ğŸ“§ ç„¡æ–°è­¦å‘Šï¼Œè·³é Email ç™¼é€")
        
        try:
            self.driver.quit()
            print("ğŸ”š ç€è¦½å™¨å·²é—œé–‰")
        except:
            pass


# ==================== ä¸»ç¨‹å¼é€²å…¥é» ====================
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš¢ æµ·äº‹å±€èˆªè¡Œè­¦å‘Šç›£æ§ç³»çµ± v2.1")
    print("   ğŸ‡¨ğŸ‡³ ä¸­åœ‹æµ·äº‹å±€ (CN_MSA)")
    print("   ğŸ‡¹ğŸ‡¼ å°ç£èˆªæ¸¯å±€ (TW_MOTC)")
    print("="*60 + "\n")
    
    TEAMS_WEBHOOK = os.getenv('TEAMS_WEBHOOK_URL')
    MAIL_USER = os.getenv('MAIL_USER')
    MAIL_PASS = os.getenv('MAIL_PASSWORD')
    TARGET_EMAIL = os.getenv('TARGET_EMAIL')
    
    print("ğŸ“‹ ç³»çµ±è¨­å®šæª¢æŸ¥:")
    print(f"  â€¢ Teams é€šçŸ¥: {'âœ… å·²è¨­å®š' if TEAMS_WEBHOOK else 'âŒ æœªè¨­å®š'}")
    print(f"  â€¢ Email é€šçŸ¥: {'âœ… å·²è¨­å®š' if (MAIL_USER and MAIL_PASS and TARGET_EMAIL) else 'âŒ æœªè¨­å®š'}")
    print(f"  â€¢ å°ç£èˆªæ¸¯å±€: {'âœ… å·²å•Ÿç”¨' if BS4_AVAILABLE else 'âŒ æœªå•Ÿç”¨'}")
    print(f"  â€¢ åœ°åœ–ç¹ªè£½: {'âœ… å·²å•Ÿç”¨' if MAPPING_AVAILABLE else 'âŒ æœªå•Ÿç”¨'}")
    print()
    
    try:
        scraper = MSANavigationWarningsScraper(
            webhook_url=TEAMS_WEBHOOK,
            enable_teams=bool(TEAMS_WEBHOOK),
            send_mode='batch',
            headless=True,
            mail_user=MAIL_USER,
            mail_pass=MAIL_PASS,
            target_email=TARGET_EMAIL,
            enable_tw=True
        )
        
        scraper.run()
        
        print("\nğŸ‰ ç³»çµ±åŸ·è¡ŒçµæŸï¼")
        print("="*60 + "\n")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
        traceback.print_exc()
        sys.exit(1)
