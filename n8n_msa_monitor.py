#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çµ±ä¸€æµ·äº‹è­¦å‘Šç›£æ§ç³»çµ± (ä¸­åœ‹æµ·äº‹å±€ + å°ç£èˆªæ¸¯å±€ + UKMTO)
æ”¯æ´ç¶“ç·¯åº¦æå–ã€Teams é€šçŸ¥ã€Email å ±å‘Š
ç‰ˆæœ¬: 3.0 - æ–°å¢ UKMTO èˆªè¡Œè­¦å‘Šä¾†æº
"""

import platform
import subprocess
import os
import sys
import ssl
import logging
import warnings
import json
import smtplib
import requests
import traceback
import re
import time
from datetime import datetime, timezone, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.image import MIMEImage
from dotenv import load_dotenv
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import urllib3
from database_manager import DatabaseManager
from keyword_manager import KeywordManager

# ==================== 1. å…¨åŸŸåˆå§‹åŒ– ====================
# åœç”¨è­¦å‘Š & SSL ç¹éï¼ˆä¼æ¥­ç¶²è·¯è‡ªç°½æ†‘è­‰ï¼‰
ssl._create_default_https_context = ssl._create_unverified_context
os.environ['WDM_SSL_VERIFY'] = '0'
load_dotenv()
warnings.filterwarnings('ignore')
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
logging.getLogger('selenium').setLevel(logging.ERROR)
logging.getLogger('urllib3').setLevel(logging.ERROR)

# éŒ¯èª¤éæ¿¾å™¨ (Windows)
if os.name == 'nt':
    class ErrorFilter:
        def __init__(self, stream):
            self.stream = stream
        def write(self, text):
            if any(k in text for k in ['ERROR:net', 'handshake failed', 'DEPRECATED_ENDPOINT']):
                return
            self.stream.write(text)
        def flush(self):
            self.stream.flush()
    sys.stderr = ErrorFilter(sys.stderr)


# ==================== 2. åº§æ¨™æå–å™¨ (å¢å¼·ç‰ˆ) ====================
class CoordinateExtractor:
    """æå–æ–‡æœ¬ä¸­çš„ç¶“ç·¯åº¦åº§æ¨™ï¼ˆå¢å¼·ç‰ˆï¼‰"""

    def __init__(self):
        self.patterns = [
            r'(\d{1,3})-(\d{1,2}\.\d+)\s*([NSnsåŒ—å—])\s+(\d{1,3})-(\d{1,2}\.\d+)\s*([EWewæ±è¥¿])',
            r'(\d{1,3})-(\d{1,2})\s*([NSnsåŒ—å—])\s+(\d{1,3})-(\d{1,2})\s*([EWewæ±è¥¿])',
            r'(\d{1,3})[Â°åº¦]\s*(\d{1,2})[\'â€²åˆ†]?\s*([NSnsåŒ—å—])\s+(\d{1,3})[Â°åº¦]\s*(\d{1,2})[\'â€²åˆ†]?\s*([EWewæ±è¥¿])',
            r'(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?\s*([NSnsåŒ—å—])\s+(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?\s*([EWewæ±è¥¿])',
            r'([NSnsåŒ—å—])\s*(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?\s+([EWewæ±è¥¿])\s*(\d{1,3})[Â°åº¦]\s*(\d{1,2}\.?\d*)[\'â€²åˆ†]?',
            r'(\d{1,3}\.\d+)\s*[Â°åº¦]?\s*([NSnsåŒ—å—])\s+(\d{1,3}\.\d+)\s*[Â°åº¦]?\s*([EWewæ±è¥¿])',
            r'[åŒ—å—ç·¯]\s*(\d{1,3})\s*åº¦\s*(\d{1,2})\s*åˆ†\s+[æ±è¥¿ç¶“]\s*(\d{1,3})\s*åº¦\s*(\d{1,2})\s*åˆ†',
        ]
        print("  ğŸ—ºï¸ åº§æ¨™æå–å™¨åˆå§‹åŒ–å®Œæˆ")

    def extract_coordinates(self, text):
        coordinates = []
        if not text:
            return coordinates
        text = text.replace('ã€', ' ').replace('ï¼Œ', ' ').replace('ã€‚', ' ')
        for pattern in self.patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    coord = self._parse_match(match, pattern)
                    if coord and self._validate_coordinate(coord):
                        coordinates.append(coord)
                except Exception:
                    continue
        unique_coords = []
        for coord in coordinates:
            is_duplicate = False
            for existing in unique_coords:
                if abs(coord[0] - existing[0]) < 0.01 and abs(coord[1] - existing[1]) < 0.01:
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_coords.append(coord)
        return unique_coords

    def _parse_match(self, match, pattern):
        groups = match.groups()
        if len(groups) == 4 and '\\.' in pattern and 'degree' not in pattern:
            try:
                lat = float(groups[0])
                lat_dir = groups[1].upper()
                lon = float(groups[2])
                lon_dir = groups[3].upper()
                if lat_dir in ['S', 's', 'å—']:
                    lat = -lat
                if lon_dir in ['W', 'w', 'è¥¿']:
                    lon = -lon
                return (lat, lon)
            except:
                return None
        if len(groups) >= 6 and groups[0] in ['N', 'S', 'n', 's', 'åŒ—', 'å—']:
            try:
                lat_dir = groups[0].upper()
                lat_deg = float(groups[1])
                lat_min = float(groups[2])
                lon_dir = groups[3].upper()
                lon_deg = float(groups[4])
                lon_min = float(groups[5])
                lat = lat_deg + lat_min / 60
                lon = lon_deg + lon_min / 60
                if lat_dir in ['S', 's', 'å—']:
                    lat = -lat
                if lon_dir in ['W', 'w', 'è¥¿']:
                    lon = -lon
                return (lat, lon)
            except:
                return None
        if len(groups) >= 6:
            try:
                lat_deg = float(groups[0])
                lat_min = float(groups[1])
                lat_dir = groups[2].upper() if len(groups[2]) > 0 else 'N'
                lon_deg = float(groups[3])
                lon_min = float(groups[4])
                lon_dir = groups[5].upper() if len(groups[5]) > 0 else 'E'
                lat = lat_deg + lat_min / 60
                lon = lon_deg + lon_min / 60
                if lat_dir in ['S', 's', 'å—']:
                    lat = -lat
                if lon_dir in ['W', 'w', 'è¥¿']:
                    lon = -lon
                return (lat, lon)
            except:
                return None
        return None

    def _validate_coordinate(self, coord):
        if not coord or len(coord) != 2:
            return False
        lat, lon = coord
        if lat < -90 or lat > 90:
            return False
        if lon < -180 or lon > 180:
            return False
        if not (-60 <= lat <= 60 and 60 <= lon <= 180):
            return False
        return True

    def extract_from_html(self, html_content):
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            content_div = soup.find('div', {'class': 'text', 'id': 'ch_p'})
            if content_div:
                text = content_div.get_text()
                return self.extract_coordinates(text)
            return self.extract_coordinates(html_content)
        except Exception as e:
            print(f"    âš ï¸ HTML è§£æå¤±æ•—: {e}")
            return []

    def format_coordinates(self, coordinates):
        if not coordinates:
            return "ç„¡åº§æ¨™è³‡è¨Š"
        formatted = []
        for lat, lon in coordinates:
            lat_dir = 'N' if lat >= 0 else 'S'
            lon_dir = 'E' if lon >= 0 else 'W'
            formatted.append(f"{abs(lat):.4f}Â°{lat_dir}, {abs(lon):.4f}Â°{lon_dir}")
        return " | ".join(formatted)


# ==================== 3. çµ±ä¸€ Teams é€šçŸ¥ç³»çµ± (å¢å¼·ç‰ˆ) ====================
class UnifiedTeamsNotifier:
    def __init__(self, webhook_url):
        self.webhook_url = webhook_url

    def _fix_url(self, url, base_domain=""):
        if not url:
            return base_domain or "https://www.msa.gov.cn/page/outter/weather.jsp"
        url = url.strip()
        if url.startswith('/'):
            return f"{base_domain}{url}" if base_domain else f"https://www.msa.gov.cn{url}"
        if url.startswith(('http://', 'https://')):
            return url
        if url.startswith(('javascript:', '#')):
            return base_domain or "https://www.msa.gov.cn/page/outter/weather.jsp"
        return f"{base_domain}/{url}" if base_domain else f"https://www.msa.gov.cn/{url}"

    def _create_adaptive_card(self, title, body_elements, actions=None):
        card_content = {
            "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
            "type": "AdaptiveCard",
            "version": "1.4",
            "body": [
                {
                    "type": "TextBlock",
                    "text": title,
                    "weight": "Bolder",
                    "size": "Large",
                    "color": "Attention"
                }
            ] + body_elements
        }
        if actions:
            card_content["actions"] = actions
        return {
            "type": "message",
            "attachments": [{
                "contentType": "application/vnd.microsoft.card.adaptive",
                "contentUrl": None,
                "content": card_content
            }]
        }

    def send_batch_notification(self, warnings_list, source_type="CN_MSA", is_today=True):
        """
        ç™¼é€æ‰¹é‡è­¦å‘Šé€šçŸ¥ (å«åº§æ¨™è³‡è¨Šï¼Œå€åˆ†ä»Šæ—¥/æ­·å²)
        source_type: CN_MSA / TW_MPB / UKMTO
        """
        if not self.webhook_url or not warnings_list:
            return False

        try:
            # æ ¹æ“šä¾†æºè¨­å®šåœ–ç¤ºå’Œåç¨±
            source_config = {
                "TW_MPB": {
                    "icon": "ğŸ‡¹ğŸ‡¼",
                    "name": "å°ç£èˆªæ¸¯å±€",
                    "home_url": "https://www.motcmpb.gov.tw/Information/Notice?SiteId=1&NodeId=483",
                    "base_domain": "https://www.motcmpb.gov.tw"
                },
                "UKMTO": {
                    "icon": "ğŸ‡¬ğŸ‡§",
                    "name": "UKMTO èˆªè¡Œè­¦å‘Š",
                    "home_url": "https://www.ukmto.org/recent-incidents",
                    "base_domain": "https://www.ukmto.org"
                },
                "CN_MSA": {
                    "icon": "ğŸ‡¨ğŸ‡³",
                    "name": "ä¸­åœ‹æµ·äº‹å±€",
                    "home_url": "https://www.msa.gov.cn/page/outter/weather.jsp",
                    "base_domain": "https://www.msa.gov.cn"
                },
            }
            cfg = source_config.get(source_type, source_config["CN_MSA"])
            source_icon = cfg["icon"]
            source_name = cfg["name"]
            home_url    = cfg["home_url"]
            base_domain = cfg["base_domain"]

            time_badge   = "ğŸ†• ä»Šæ—¥æ–°å¢" if is_today else "ğŸ“š æ­·å²è³‡æ–™ (è¿‘30å¤©)"
            title_color  = "Attention" if is_today else "Good"

            body_elements = [
                {
                    "type": "TextBlock",
                    "text": f"{source_icon} **{source_name}** | {time_badge}",
                    "size": "Medium",
                    "weight": "Bolder",
                    "color": title_color
                },
                {
                    "type": "TextBlock",
                    "text": f"ç™¼ç¾ **{len(warnings_list)}** å€‹èˆªè¡Œè­¦å‘Š",
                    "size": "Medium"
                },
                {
                    "type": "TextBlock",
                    "text": "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
                    "wrap": True
                }
            ]

            actions = []

            for idx, w in enumerate(warnings_list[:8], 1):
                _, bureau, title, link, pub_time, _, _, coordinates = w
                fixed_link = self._fix_url(link, base_domain)

                coord_summary = "ç„¡åº§æ¨™"
                if coordinates:
                    try:
                        coord_list = json.loads(coordinates) if isinstance(coordinates, str) else coordinates
                        if coord_list:
                            coord_summary = f"ğŸ“ {len(coord_list)} å€‹åº§æ¨™é»"
                    except:
                        coord_summary = "åº§æ¨™æ ¼å¼éŒ¯èª¤"

                body_elements.extend([
                    {
                        "type": "TextBlock",
                        "text": f"**{idx}. {bureau}**",
                        "weight": "Bolder",
                        "color": "Accent",
                        "spacing": "Medium"
                    },
                    {
                        "type": "TextBlock",
                        "text": title[:100],
                        "wrap": True
                    },
                    {
                        "type": "TextBlock",
                        "text": f"ğŸ“… {pub_time} | {coord_summary}",
                        "size": "Small",
                        "isSubtle": True
                    }
                ])

                if len(actions) < 4:
                    actions.append({
                        "type": "Action.OpenUrl",
                        "title": f"ğŸ“„ å…¬å‘Š {idx}",
                        "url": fixed_link
                    })

            if len(warnings_list) > 8:
                body_elements.append({
                    "type": "TextBlock",
                    "text": f"*...é‚„æœ‰ {len(warnings_list)-8} ç­†æœªé¡¯ç¤º*",
                    "isSubtle": True
                })

            actions.append({
                "type": "Action.OpenUrl",
                "title": f"ğŸ  {source_name}é¦–é ",
                "url": home_url
            })

            card_title = f"{'ğŸš¨' if is_today else 'ğŸ“‹'} {source_name} - {time_badge} ({len(warnings_list)})"
            payload = self._create_adaptive_card(card_title, body_elements, actions)

            print(f"  ğŸ“¤ æ­£åœ¨ç™¼é€ Teams é€šçŸ¥ [{time_badge}] åˆ°: {self.webhook_url[:50]}...")

            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30,
                verify=False
            )

            if response.status_code in [200, 202]:
                print(f"âœ… {source_name} Teams é€šçŸ¥ç™¼é€æˆåŠŸ [{time_badge}] ({len(warnings_list)} ç­†)")
                return True
            else:
                print(f"âŒ {source_name} Teams é€šçŸ¥å¤±æ•—: HTTP {response.status_code}")
                print(f"   å›æ‡‰å…§å®¹: {response.text[:200]}")
                return False

        except requests.exceptions.SSLError as e:
            print(f"âŒ Teams SSL éŒ¯èª¤: {e}")
            return False
        except requests.exceptions.Timeout as e:
            print(f"âŒ Teams é€£ç·šé€¾æ™‚: {e}")
            return False
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ Teams é€£ç·šéŒ¯èª¤: {e}")
            return False
        except Exception as e:
            print(f"âŒ Teams ç™¼é€å¤±æ•—: {e}")
            traceback.print_exc()
            return False


# ==================== 4. Email é€šçŸ¥ç³»çµ± (å¢å¼·ç‰ˆ) ====================
class GmailRelayNotifier:
    """Gmail SMTP éƒµä»¶é€šçŸ¥ç³»çµ±"""

    def __init__(self, mail_user, mail_pass, target_email):
        self.mail_user    = mail_user
        self.mail_pass    = mail_pass
        self.target_email = target_email
        self.smtp_server  = "smtp.gmail.com"
        self.smtp_port    = 587

        if not all([mail_user, mail_pass, target_email]):
            print("âš ï¸ Email é€šçŸ¥æœªå®Œæ•´è¨­å®š")
            self.enabled = False
        else:
            self.enabled = True
            print("âœ… Email é€šçŸ¥ç³»çµ±å·²å•Ÿç”¨")

    def send_trigger_email(self, today_warnings, history_warnings):
        if not self.enabled:
            print("â„¹ï¸ Email é€šçŸ¥æœªå•Ÿç”¨")
            return False
        try:
            msg = MIMEMultipart('related')
            total_count = len(today_warnings) + len(history_warnings)
            today_count = len(today_warnings)
            msg['Subject'] = (
                f"ğŸŒŠ èˆªè¡Œè­¦å‘Šç›£æ§å ±å‘Š - å…±{total_count}ç­† (ä»Šæ—¥{today_count}ç­†) - "
                f"{(datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M')}(TPE)"
            )
            msg['From'] = self.mail_user
            msg['To']   = self.target_email

            html_content = self._generate_html_report(today_warnings, history_warnings)
            msg_alternative = MIMEMultipart('alternative')
            msg.attach(msg_alternative)
            msg_alternative.attach(MIMEText(html_content, 'html', 'utf-8'))

            print(f"ğŸ“§ æ­£åœ¨ç™¼é€éƒµä»¶è‡³ {self.target_email}...")
            with smtplib.SMTP(self.smtp_server, self.smtp_port, timeout=30) as server:
                server.starttls()
                server.login(self.mail_user, self.mail_pass)
                server.send_message(msg)
            print("âœ… éƒµä»¶ç™¼é€æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ éƒµä»¶ç™¼é€å¤±æ•—: {e}")
            traceback.print_exc()
            return False

    def _source_icon(self, source):
        return {"TW_MPB": "ğŸ‡¹ğŸ‡¼", "UKMTO": "ğŸ‡¬ğŸ‡§"}.get(source, "ğŸ‡¨ğŸ‡³")

    def _generate_html_report(self, today_warnings, history_warnings):
        total_count = len(today_warnings) + len(history_warnings)

        html = f"""
        <html>
        <head>
            <meta charset="utf-8">
            <style>
                body {{ font-family: 'Microsoft JhengHei', Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
                .container {{ max-width: 1000px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                h1 {{ color: #003366; border-bottom: 3px solid #0066cc; padding-bottom: 10px; }}
                h2 {{ color: #0066cc; margin-top: 30px; padding: 10px; background: #f0f8ff; border-left: 4px solid #0066cc; }}
                .summary {{ background: #e3f2fd; padding: 15px; border-radius: 5px; margin: 20px 0; }}
                .summary-item {{ display: inline-block; margin: 5px 15px 5px 0; font-weight: bold; }}
                .warning-item {{ background: #f9f9f9; padding: 15px; margin: 15px 0; border-left: 4px solid #0066cc; border-radius: 5px; }}
                .warning-item.today {{ border-left-color: #ff6b6b; background: #fff5f5; }}
                .warning-item.history {{ border-left-color: #51cf66; background: #f0fff4; }}
                .warning-title {{ font-weight: bold; color: #003366; font-size: 16px; }}
                .warning-meta {{ color: #666; font-size: 14px; margin-top: 5px; }}
                .coordinates {{ background: #e3f2fd; padding: 10px; margin-top: 10px; border-radius: 5px; font-family: 'Courier New', monospace; font-size: 13px; }}
                .coord-item {{ margin: 3px 0; }}
                .footer {{ margin-top: 30px; padding-top: 20px; border-top: 1px solid #ddd; color: #666; font-size: 12px; text-align: center; }}
                .badge {{ display: inline-block; padding: 3px 8px; border-radius: 3px; font-size: 12px; font-weight: bold; margin-left: 10px; }}
                .badge.today {{ background: #ff6b6b; color: white; }}
                .badge.history {{ background: #51cf66; color: white; }}
                .badge.ukmto {{ background: #6c5ce7; color: white; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>ğŸŒŠ æµ·äº‹è­¦å‘Šç›£æ§å ±å‘Š</h1>
                <div class="summary">
                    <div class="summary-item">ğŸ“… å ±å‘Šæ™‚é–“ï¼š{(datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M')} (TPE)</div><br>
                    <div class="summary-item">ğŸ“Š ç¸½è­¦å‘Šæ•¸ï¼š{total_count} ç­†</div>
                    <div class="summary-item">ğŸ†• ä»Šæ—¥æ–°å¢ï¼š{len(today_warnings)} ç­†</div>
                    <div class="summary-item">ğŸ“š æ­·å²è³‡æ–™ï¼š{len(history_warnings)} ç­†</div>
                </div>
        """

        def _render_warnings(warnings_list, badge_class, badge_label):
            result = ""
            for idx, w in enumerate(warnings_list, 1):
                source = w.get('source', '')
                icon   = self._source_icon(source)
                coords = w.get('coordinates', [])
                coord_html = ""
                if coords:
                    coord_html = '<div class="coordinates"><strong>ğŸ“ åº§æ¨™è³‡è¨Šï¼š</strong><br>'
                    for i, (lat, lon) in enumerate(coords, 1):
                        lat_dir = 'N' if lat >= 0 else 'S'
                        lon_dir = 'E' if lon >= 0 else 'W'
                        coord_html += f'<div class="coord-item">{i}. {abs(lat):.4f}Â°{lat_dir}, {abs(lon):.4f}Â°{lon_dir}</div>'
                    coord_html += '</div>'

                # UKMTO ç‰¹æœ‰æ¬„ä½
                extra_meta = ""
                if source == "UKMTO":
                    colour = w.get('colour', '')
                    colour_icon = "ğŸ”´" if colour == "Red" else "ğŸŸ¡"
                    extra_meta = f"âš ï¸ è­¦ç¤ºç­‰ç´šï¼š{colour_icon} {colour}<br>"

                kw = w.get('keywords', [])
                kw_str = ', '.join(kw) if isinstance(kw, list) else str(kw)

                result += f"""
                    <div class="warning-item {badge_class}">
                        <div class="warning-title">
                            <span>{icon}</span> {idx}. {w.get('title', 'N/A')}
                            <span class="badge {badge_class}">{badge_label}</span>
                        </div>
                        <div class="warning-meta">
                            ğŸ“‹ ç™¼å¸ƒå–®ä½ï¼š{w.get('bureau', 'N/A')}<br>
                            ğŸ“… ç™¼å¸ƒæ™‚é–“ï¼š{w.get('time', 'N/A')}<br>
                            {extra_meta}
                            ğŸ”‘ é—œéµå­—ï¼š{kw_str}<br>
                            ğŸ”— <a href="{w.get('link', '#')}">æŸ¥çœ‹è©³æƒ…</a>
                        </div>
                        {coord_html}
                    </div>
                """
            return result

        if today_warnings:
            html += f"<h2>ğŸ†• ä»Šæ—¥æ–°å¢è­¦å‘Š ({len(today_warnings)} ç­†)</h2>"
            html += _render_warnings(today_warnings, "today", "ä»Šæ—¥")

        if history_warnings:
            html += f"<h2>ğŸ“š æ­·å²è³‡æ–™ ({len(history_warnings)} ç­†)</h2>"
            html += _render_warnings(history_warnings, "history", "æ­·å²")

        html += """
                <div class="footer">
                    <p>æ­¤ç‚ºè‡ªå‹•ç™¼é€çš„éƒµä»¶ï¼Œè«‹å‹¿ç›´æ¥å›è¦†</p>
                    <p>èˆªè¡Œè­¦å‘Šç›£æ§ç³»çµ± v3.0 | Navigation Warning Monitor System</p>
                </div>
            </div>
        </body>
        </html>
        """
        return html


# ==================== 5. UKMTO çˆ¬èŸ² ====================
class UKMTOScraper:
    """
    çˆ¬å– UKMTO (United Kingdom Maritime Trade Operations) èˆªè¡Œè­¦å‘Š
    ä¾†æº: https://www.ukmto.org/recent-incidents
    ç¯©é¸: éå» N å¤© (é è¨­ 30 å¤©)
    """

    URL = "https://www.ukmto.org/recent-incidents"

    # UKMTO é é¢æ—¥æœŸæ ¼å¼: "2 March 2026"
    MONTH_MAP = {
        "January": 1, "February": 2, "March": 3,    "April": 4,
        "May": 5,     "June": 6,     "July": 7,      "August": 8,
        "September": 9, "October": 10, "November": 11, "December": 12,
    }

    def __init__(self, db_manager, keyword_manager, teams_notifier, coord_extractor, days=30):
        self.db_manager       = db_manager
        self.keyword_manager  = keyword_manager
        self.keywords         = keyword_manager.get_keywords()
        self.teams_notifier   = teams_notifier
        self.coord_extractor  = coord_extractor
        self.days             = days

        now = datetime.now(tz=timezone.utc)
        self.cutoff_date  = now - timedelta(days=days)
        self.today_start  = now.replace(hour=0, minute=0, second=0, microsecond=0)

        self.new_warnings_today   = []
        self.new_warnings_history = []
        self.captured_warnings_today   = []
        self.captured_warnings_history = []

        print(f"  ğŸ‡¬ğŸ‡§ UKMTO çˆ¬èŸ²è¨­å®š:")
        print(f"     - æŠ“å–ç¯„åœ: æœ€è¿‘ {days} å¤© (å¾ {self.cutoff_date.strftime('%Y-%m-%d')} èµ·)")
        print(f"     - ä»Šæ—¥å®šç¾©: {self.today_start.strftime('%Y-%m-%d')} 00:00 UTC èµ·")

        # â”€â”€ åˆå§‹åŒ– WebDriver â”€â”€
        print("  ğŸŒ æ­£åœ¨å•Ÿå‹• Chrome WebDriver (UKMTO)...")
        self.driver = self._init_driver()
        self.wait   = WebDriverWait(self.driver, 20)
        print("  âœ… WebDriver å•Ÿå‹•æˆåŠŸ (UKMTO)")

    # ------------------------------------------------------------------
    # WebDriver åˆå§‹åŒ–ï¼ˆå« SSL ç¹é & è‡ªå‹•å°‹æ‰¾ chromedriverï¼‰
    # ------------------------------------------------------------------
    def _init_driver(self) -> webdriver.Chrome:
        options = webdriver.ChromeOptions()
        options.add_argument("--headless=new")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("--ignore-certificate-errors")
        options.add_argument("--ignore-ssl-errors=yes")
        options.add_argument("--allow-insecure-localhost")
        options.add_argument(
            "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        options.add_experimental_option('excludeSwitches', ['enable-logging', 'enable-automation'])
        options.add_experimental_option('useAutomationExtension', False)

        driver_path = self._find_chromedriver()
        if driver_path:
            service = Service(executable_path=driver_path)
        else:
            service = Service()  # å¾ PATH å°‹æ‰¾

        if platform.system() == 'Windows':
            service.creation_flags = subprocess.CREATE_NO_WINDOW

        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(60)
        return driver

    def _find_chromedriver(self) -> str | None:
        """ä¾åºå˜—è©¦å¤šç¨®æ–¹å¼å–å¾— chromedriver è·¯å¾‘"""
        # 1. ç’°å¢ƒè®Šæ•¸
        env_path = os.environ.get("CHROMEDRIVER_PATH")
        if env_path and os.path.exists(env_path):
            return env_path

        # 2. å¸¸è¦‹ Windows è·¯å¾‘
        common_paths = [
            r"C:\chromedriver\chromedriver.exe",
            r"C:\Program Files\Google\Chrome\Application\chromedriver.exe",
            os.path.join(os.environ.get("LOCALAPPDATA", ""), "Google", "Chrome", "Application", "chromedriver.exe"),
            os.path.join(os.environ.get("USERPROFILE", ""), "chromedriver.exe"),
            os.path.join(os.environ.get("USERPROFILE", ""), "Downloads", "chromedriver.exe"),
            "chromedriver.exe",
            "chromedriver",
        ]
        for p in common_paths:
            if p and os.path.exists(p):
                return p

        # 3. webdriver_managerï¼ˆSSL å·²ç¹éï¼‰
        try:
            path = ChromeDriverManager().install()
            return path
        except Exception as e:
            print(f"  âš ï¸  webdriver_manager å¤±æ•—: {e}")

        return None

    # ------------------------------------------------------------------
    # æ—¥æœŸè§£æ
    # ------------------------------------------------------------------
    def _parse_date(self, date_str: str) -> datetime | None:
        """å°‡ '2 March 2026' è§£æç‚º UTC-aware datetime"""
        parts = date_str.strip().split()
        if len(parts) != 3:
            return None
        try:
            day   = int(parts[0])
            month = self.MONTH_MAP.get(parts[1])
            year  = int(parts[2])
            if not month:
                return None
            return datetime(year, month, day, tzinfo=timezone.utc)
        except (ValueError, TypeError):
            return None

    # ------------------------------------------------------------------
    # ä¸»è¦çˆ¬å–é‚è¼¯
    # ------------------------------------------------------------------
    def scrape(self):
        """çˆ¬å– UKMTO éå» N å¤©çš„èˆªè¡Œè­¦å‘Š"""
        print(f"\nğŸ‡¬ğŸ‡§ é–‹å§‹çˆ¬å– UKMTO èˆªè¡Œè­¦å‘Š...")
        print(f"  ğŸŒ ç›®æ¨™ç¶²å€: {self.URL}")

        try:
            self.driver.get(self.URL)

            # ç­‰å¾…äº‹ä»¶åˆ—è¡¨è¼‰å…¥
            self.wait.until(
                EC.presence_of_element_located(
                    (By.CSS_SELECTOR, "ul.IncidentList_incidentList__NGsl0")
                )
            )
            print("  âœ… é é¢è¼‰å…¥å®Œæˆï¼Œé–‹å§‹è§£æ...")
            time.sleep(2)

            li_elements = self.driver.find_elements(
                By.CSS_SELECTOR,
                "ul.IncidentList_incidentList__NGsl0 > li.IncidentList_incident__HgGtN"
            )
            print(f"  ğŸ“‹ å…±æ‰¾åˆ° {len(li_elements)} ç­†äº‹ä»¶ï¼Œç¯©é¸æœ€è¿‘ {self.days} å¤©...")

            for elem in li_elements:
                try:
                    self._process_incident(elem)
                except Exception as e:
                    print(f"  âš ï¸ è™•ç†äº‹ä»¶æ™‚å‡ºéŒ¯: {e}")
                    continue

        except Exception as e:
            print(f"  âŒ UKMTO çˆ¬å–éŒ¯èª¤: {e}")
            traceback.print_exc()
        finally:
            try:
                self.driver.quit()
                print("  ğŸ”’ WebDriver å·²é—œé–‰ (UKMTO)")
            except:
                pass

        total_new = len(self.new_warnings_today) + len(self.new_warnings_history)
        print(f"\nğŸ‡¬ğŸ‡§ UKMTO çˆ¬å–å®Œæˆ:")
        print(f"   ğŸ†• ä»Šæ—¥æ–°å¢: {len(self.new_warnings_today)} ç­†")
        print(f"   ğŸ“š æ­·å²è³‡æ–™: {len(self.new_warnings_history)} ç­†")
        print(f"   ğŸ“Š ç¸½è¨ˆ: {total_new} ç­†")

        return {
            'today':   self.new_warnings_today,
            'history': self.new_warnings_history
        }

    def _process_incident(self, elem):
        """è™•ç†å–®ä¸€äº‹ä»¶ <li> å…ƒç´ """

        # â”€â”€ äº‹ä»¶ ID â”€â”€
        incident_id = elem.get_attribute("id") or "N/A"

        # â”€â”€ æ¨™é¡Œ â”€â”€
        try:
            title = elem.find_element(
                By.CSS_SELECTOR, "h3.IncidentList_title__cOmOY button"
            ).text.strip()
        except Exception:
            title = "N/A"

        # â”€â”€ è­¦ç¤ºé¡è‰² (Red / Yellow) â”€â”€
        try:
            colour = elem.find_element(
                By.CSS_SELECTOR, "span.Pin_pin__dpf_F"
            ).get_attribute("data-colour") or "N/A"
        except Exception:
            colour = "N/A"

        # â”€â”€ æ—¥æœŸ â”€â”€
        try:
            date_str = elem.find_element(
                By.CSS_SELECTOR, "ul.IncidentList_meta__JmhSj li span"
            ).text.strip()
            incident_date = self._parse_date(date_str)
        except Exception:
            date_str = "N/A"
            incident_date = None

        # â”€â”€ å…§å®¹ â”€â”€
        try:
            details = elem.find_element(
                By.CSS_SELECTOR, "p.IncidentList_details__bwUAz"
            ).text.strip()
        except Exception:
            details = "N/A"

        # â”€â”€ æ—¥æœŸç¯©é¸ â”€â”€
        if incident_date is None:
            print(f"  âš ï¸  è·³éï¼ˆæ—¥æœŸç„¡æ³•è§£æï¼‰ï¼š{title}")
            return

        if incident_date < self.cutoff_date:
            # åˆ—è¡¨ç‚ºæ™‚é–“å€’åºï¼Œè¶…éæˆªæ­¢æ—¥å³å¯åœæ­¢
            raise StopIteration(f"è¶…å‡ºç¯„åœï¼Œåœæ­¢ï¼ˆ{date_str}ï¼‰")

        is_today   = incident_date >= self.today_start
        time_label = "ğŸ†• ä»Šæ—¥" if is_today else "ğŸ“š æ­·å²"
        colour_icon = "ğŸ”´" if colour == "Red" else "ğŸŸ¡"
        print(f"  {time_label} {colour_icon} [{date_str}] {title}")

        # â”€â”€ åº§æ¨™æå–ï¼ˆå¾ details æ–‡å­—ï¼‰â”€â”€
        coordinates = self.coord_extractor.extract_coordinates(details)
        if coordinates:
            print(f"    ğŸ“ å¾å…§å®¹æå–åˆ° {len(coordinates)} å€‹åº§æ¨™")

        # â”€â”€ é—œéµå­—æ¯”å°ï¼ˆUKMTO æ¨™é¡Œæœ¬èº«å³ç‚ºé¡å‹ï¼Œç›´æ¥ç”¨æ¨™é¡Œ + å…§å®¹ï¼‰â”€â”€
        matched_keywords = [k for k in self.keywords if k.lower() in (title + " " + details).lower()]
        # è‹¥ç„¡ä»»ä½•é—œéµå­—å‘½ä¸­ï¼Œä»ä¿ç•™ï¼ˆUKMTO æœ¬èº«å³ç‚ºèˆªè¡Œè­¦å‘Šï¼Œå…¨éƒ¨æ”¶éŒ„ï¼‰
        if not matched_keywords:
            matched_keywords = ["UKMTO"]

        # â”€â”€ å­˜å…¥è³‡æ–™åº« â”€â”€
        db_data = (
            "UKMTO",          # bureau
            title,
            self.URL,         # linkï¼ˆUKMTO ç„¡å€‹åˆ¥é é¢é€£çµï¼ŒæŒ‡å‘åˆ—è¡¨é ï¼‰
            date_str,
            ', '.join(matched_keywords),
            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            coordinates
        )

        is_new, w_id = self.db_manager.save_warning(db_data, source_type="UKMTO")

        if is_new and w_id:
            warning_data = {
                'id':          w_id,
                'bureau':      "UKMTO",
                'title':       title,
                'link':        self.URL,
                'time':        date_str,
                'keywords':    matched_keywords,
                'source':      'UKMTO',
                'colour':      colour,       # Red / Yellowï¼ˆUKMTO ç‰¹æœ‰ï¼‰
                'coordinates': coordinates
            }

            if is_today:
                self.new_warnings_today.append(w_id)
                self.captured_warnings_today.append(warning_data)
                print(f"    ğŸ’¾ æ–°è³‡æ–™å·²å­˜å…¥ [ä»Šæ—¥] (ID: {w_id})")
            else:
                self.new_warnings_history.append(w_id)
                self.captured_warnings_history.append(warning_data)
                print(f"    ğŸ’¾ æ–°è³‡æ–™å·²å­˜å…¥ [æ­·å²] (ID: {w_id})")
        else:
            print(f"    â„¹ï¸  è³‡æ–™å·²å­˜åœ¨")

    # ------------------------------------------------------------------
    # è®“ scrape() èƒ½æ­£ç¢ºæ•æ‰ StopIteration
    # ------------------------------------------------------------------
    def scrape(self):
        print(f"\nğŸ‡¬ğŸ‡§ é–‹å§‹çˆ¬å– UKMTO èˆªè¡Œè­¦å‘Š...")
        print(f"  ğŸŒ ç›®æ¨™ç¶²å€: {self.URL}")

        try:
            self.driver.get(self.URL)
            self.wait.until(
                EC.presence_of_element_located(
                    (By.CSS_SELECTOR, "ul.IncidentList_incidentList__NGsl0")
                )
            )
            print("  âœ… é é¢è¼‰å…¥å®Œæˆï¼Œé–‹å§‹è§£æ...")
            time.sleep(2)

            li_elements = self.driver.find_elements(
                By.CSS_SELECTOR,
                "ul.IncidentList_incidentList__NGsl0 > li.IncidentList_incident__HgGtN"
            )
            print(f"  ğŸ“‹ å…±æ‰¾åˆ° {len(li_elements)} ç­†äº‹ä»¶ï¼Œç¯©é¸æœ€è¿‘ {self.days} å¤©...")

            for elem in li_elements:
                try:
                    self._process_incident(elem)
                except StopIteration as si:
                    print(f"  â­ï¸  {si}")
                    break
                except Exception as e:
                    print(f"  âš ï¸  è™•ç†äº‹ä»¶æ™‚å‡ºéŒ¯: {e}")
                    continue

        except Exception as e:
            print(f"  âŒ UKMTO çˆ¬å–éŒ¯èª¤: {e}")
            traceback.print_exc()
        finally:
            try:
                self.driver.quit()
                print("  ğŸ”’ WebDriver å·²é—œé–‰ (UKMTO)")
            except:
                pass

        total_new = len(self.new_warnings_today) + len(self.new_warnings_history)
        print(f"\nğŸ‡¬ğŸ‡§ UKMTO çˆ¬å–å®Œæˆ:")
        print(f"   ğŸ†• ä»Šæ—¥æ–°å¢: {len(self.new_warnings_today)} ç­†")
        print(f"   ğŸ“š æ­·å²è³‡æ–™: {len(self.new_warnings_history)} ç­†")
        print(f"   ğŸ“Š ç¸½è¨ˆ: {total_new} ç­†")

        return {
            'today':   self.new_warnings_today,
            'history': self.new_warnings_history
        }


# ==================== 6. å°ç£èˆªæ¸¯å±€çˆ¬èŸ² (å¢å¼·ç‰ˆ) ====================
class TWMaritimePortBureauScraper:
    def __init__(self, db_manager, keyword_manager, teams_notifier, coord_extractor, days=3):
        self.db_manager      = db_manager
        self.keyword_manager = keyword_manager
        self.keywords        = keyword_manager.get_keywords()
        self.teams_notifier  = teams_notifier
        self.coord_extractor = coord_extractor

        self.base_url    = "https://www.motcmpb.gov.tw/Information/Notice?SiteId=1&NodeId=483"
        self.days        = days
        self.cutoff_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=days)
        self.today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

        self.new_warnings_today        = []
        self.new_warnings_history      = []
        self.captured_warnings_today   = []
        self.captured_warnings_history = []

        self.target_categories = {'333': 'ç¤™èˆªå…¬å‘Š', '334': 'å°„æ“Šå…¬å‘Š'}

        print(f"  ğŸ“… å°ç£èˆªæ¸¯å±€çˆ¬èŸ²è¨­å®š:")
        print(f"     - æŠ“å–ç¯„åœ: æœ€è¿‘ {days} å¤© (å¾ {self.cutoff_date.strftime('%Y-%m-%d')} èµ·)")
        print(f"     - ä»Šæ—¥å®šç¾©: {self.today_start.strftime('%Y-%m-%d')} 00:00 èµ·")

        print("  ğŸŒ æ­£åœ¨å•Ÿå‹• Chrome WebDriver (å°ç£èˆªæ¸¯å±€)...")
        options = webdriver.ChromeOptions()
        options.add_argument('--headless=new')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        prefs = {'profile.default_content_setting_values.notifications': 2}
        options.add_experimental_option('prefs', prefs)
        options.add_experimental_option('excludeSwitches', ['enable-logging', 'enable-automation'])
        options.add_experimental_option('useAutomationExtension', False)

        try:
            service = Service(ChromeDriverManager().install())
            if platform.system() == 'Windows':
                service.creation_flags = subprocess.CREATE_NO_WINDOW
            self.driver = webdriver.Chrome(service=service, options=options)
            self.driver.set_page_load_timeout(60)
            self.wait = WebDriverWait(self.driver, 20)
            print("  âœ… WebDriver å•Ÿå‹•æˆåŠŸ (å°ç£èˆªæ¸¯å±€)")
        except Exception as e:
            print(f"  âŒ WebDriver å•Ÿå‹•å¤±æ•—: {e}")
            raise

    def check_keywords(self, text):
        if not text:
            return []
        matched = []
        for k in self.keywords:
            if k.lower() in text.lower():
                matched.append(k)
        if 'ç¤™èˆª' in text and 'ç¤™èˆª' not in matched:
            matched.append('ç¤™èˆª')
        if 'å°„æ“Š' in text and 'å°„æ“Š' not in matched:
            matched.append('å°„æ“Š')
        return matched

    def parse_date(self, date_string):
        try:
            date_string = date_string.strip()
            date_match = re.match(r'^(\d{2,4})[/-](\d{1,2})[/-](\d{1,2})$', date_string)
            if date_match:
                year  = int(date_match.group(1))
                month = int(date_match.group(2))
                day   = int(date_match.group(3))
                if year < 1000:
                    year += 1911
                return datetime(year, month, day)
            return None
        except Exception:
            return None

    def is_within_date_range(self, date_string):
        if not date_string:
            return None, False
        parsed_date = self.parse_date(date_string)
        if parsed_date:
            if parsed_date < self.cutoff_date:
                return None, False
            is_today = parsed_date >= self.today_start
            return parsed_date, is_today
        return None, False

    def click_category_tab(self, category_id):
        try:
            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tabs a")))
            if category_id:
                tab_xpath = f"//div[@class='tabs']//a[@data-val='{category_id}']"
                tab = self.wait.until(EC.element_to_be_clickable((By.XPATH, tab_xpath)))
            else:
                tab_xpath = "//div[@class='tabs']//a[@class='active']"
                tab = self.driver.find_element(By.XPATH, tab_xpath)
            self.driver.execute_script("arguments[0].scrollIntoView(true);", tab)
            time.sleep(0.5)
            self.driver.execute_script("arguments[0].click();", tab)
            print(f"    âœ… å·²é»æ“Šåˆ†é¡æ¨™ç±¤")
            time.sleep(3)
            return True
        except Exception as e:
            print(f"    âš ï¸ é»æ“Šåˆ†é¡æ¨™ç±¤å¤±æ•—: {e}")
            return False

    def get_notices_selenium(self, page=1, base_category_id=None):
        try:
            category_name = self.target_categories.get(base_category_id, 'å…¨éƒ¨') if base_category_id else 'å…¨éƒ¨'
            print(f"  æ­£åœ¨è«‹æ±‚å°ç£èˆªæ¸¯å±€ [{category_name}] ç¬¬ {page} é ...")

            if page == 1:
                print(f"    ğŸŒ è¼‰å…¥ä¸»é é¢...")
                self.driver.get(self.base_url)
                time.sleep(3)
                if base_category_id:
                    if not self.click_category_tab(base_category_id):
                        return {'has_data': False, 'notices': [], 'processed': 0}
            else:
                try:
                    next_button = self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "li.next a")))
                    self.driver.execute_script("arguments[0].scrollIntoView(true);", next_button)
                    time.sleep(0.5)
                    self.driver.execute_script("arguments[0].click();", next_button)
                    print(f"    âœ… å·²é»æ“Šä¸‹ä¸€é ")
                    time.sleep(3)
                except Exception as e:
                    print(f"    âš ï¸ ç„¡æ³•ç¿»é : {e}")
                    return {'has_data': False, 'notices': [], 'processed': 0}

            try:
                self.wait.until(EC.presence_of_element_located((By.ID, "table")))
                self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "#table dl")))
                print(f"    âœ… é é¢å…§å®¹è¼‰å…¥å®Œæˆ")
            except Exception as e:
                print(f"    âš ï¸ ç­‰å¾…å…§å®¹è¼‰å…¥è¶…æ™‚: {e}")
                return {'has_data': False, 'notices': [], 'processed': 0}

            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            table_div = soup.find('div', id='table')
            if not table_div:
                return {'has_data': False, 'notices': [], 'processed': 0}

            contents_div = table_div.find('div', class_='contents')
            if not contents_div:
                return {'has_data': False, 'notices': [], 'processed': 0}

            all_dl_list  = contents_div.find_all('dl')
            data_dl_list = [dl for dl in all_dl_list if 'con-title' not in dl.get('class', [])]
            print(f"    ğŸ“‹ æ‰¾åˆ° {len(data_dl_list)} å€‹è³‡æ–™åˆ—")

            if len(data_dl_list) == 0:
                return {'has_data': False, 'notices': [], 'processed': 0}

            processed_count = 0

            for idx, dl in enumerate(data_dl_list, 1):
                try:
                    dt_list = dl.find_all('dt')
                    dd = dl.find('dd')
                    if len(dt_list) < 2 or not dd:
                        continue

                    processed_count += 1
                    number = dt_list[0].get_text(strip=True)
                    date   = dt_list[1].get_text(strip=True)
                    unit   = dt_list[2].get_text(strip=True) if len(dt_list) > 2 else 'å°ç£èˆªæ¸¯å±€'

                    link_tag = dd.find('a')
                    if link_tag:
                        title = link_tag.get_text(strip=True)
                        link  = link_tag.get('href', '')
                        if link and not link.startswith('http'):
                            link = f"https://www.motcmpb.gov.tw{link}" if link.startswith('/') else f"https://www.motcmpb.gov.tw/{link}"
                    else:
                        title = dd.get_text(strip=True)
                        link  = ''

                    print(f"    [{idx}] {number} | {date} | {title[:40]}...")

                    parsed_date, is_today = self.is_within_date_range(date)
                    if parsed_date is None:
                        print(f"        â­ï¸ æ—¥æœŸè¶…å‡ºç¯„åœ: {date}")
                        continue

                    time_label = "ğŸ†• ä»Šæ—¥" if is_today else "ğŸ“š æ­·å²"
                    print(f"        {time_label} è³‡æ–™: {date}")

                    matched_keywords = self.check_keywords(title)
                    if not matched_keywords:
                        print(f"        â­ï¸ ç„¡é—œéµå­—åŒ¹é…")
                        continue
                    print(f"        âœ… é—œéµå­—åŒ¹é…: {', '.join(matched_keywords)}")

                    print(f"        ğŸ“ æ­£åœ¨æå–åº§æ¨™...")
                    coordinates = []
                    title_coords = self.coord_extractor.extract_coordinates(title)
                    if title_coords:
                        coordinates.extend(title_coords)
                        print(f"          âœ… å¾æ¨™é¡Œæå–åˆ° {len(title_coords)} å€‹åº§æ¨™")

                    if link:
                        try:
                            self.driver.execute_script("window.open('');")
                            self.driver.switch_to.window(self.driver.window_handles[1])
                            self.driver.set_page_load_timeout(10)
                            self.driver.get(link)
                            time.sleep(2)
                            detail_soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                            content_div = (
                                detail_soup.find('div', class_='editor_Content') or
                                detail_soup.find('div', class_='content') or
                                detail_soup.find('div', id='content') or
                                detail_soup.find('article') or
                                detail_soup.find('div', id='container')
                            )
                            if content_div:
                                page_coords = self.coord_extractor.extract_coordinates(content_div.get_text())
                                for pc in page_coords:
                                    if pc not in coordinates:
                                        coordinates.append(pc)
                                if page_coords:
                                    print(f"          âœ… å¾é é¢æå–åˆ° {len(page_coords)} å€‹åº§æ¨™")
                            self.driver.close()
                            self.driver.switch_to.window(self.driver.window_handles[0])
                            self.driver.set_page_load_timeout(60)
                            time.sleep(1)
                        except Exception as e:
                            print(f"          âš ï¸ ç„¡æ³•å¾ç¶²é æå–åº§æ¨™: {e}")
                            try:
                                if len(self.driver.window_handles) > 1:
                                    self.driver.close()
                                    self.driver.switch_to.window(self.driver.window_handles[0])
                                    self.driver.set_page_load_timeout(60)
                            except:
                                pass

                    if coordinates:
                        print(f"        ğŸ“ ç¸½å…±æå–åˆ° {len(coordinates)} å€‹åº§æ¨™")
                    else:
                        print(f"        â„¹ï¸ æœªæ‰¾åˆ°åº§æ¨™è³‡è¨Š")

                    db_data = (unit, title, link, date, ', '.join(matched_keywords), datetime.now().strftime('%Y-%m-%d %H:%M:%S'), coordinates)
                    is_new, w_id = self.db_manager.save_warning(db_data, source_type="TW_MPB")

                    if is_new and w_id:
                        warning_data = {
                            'id': w_id, 'bureau': unit, 'title': title, 'link': link,
                            'time': date, 'keywords': matched_keywords,
                            'source': 'TW_MPB', 'category': category_name, 'coordinates': coordinates
                        }
                        if is_today:
                            self.new_warnings_today.append(w_id)
                            self.captured_warnings_today.append(warning_data)
                            print(f"        ğŸ’¾ æ–°è³‡æ–™å·²å­˜å…¥ [ä»Šæ—¥] (ID: {w_id})")
                        else:
                            self.new_warnings_history.append(w_id)
                            self.captured_warnings_history.append(warning_data)
                            print(f"        ğŸ’¾ æ–°è³‡æ–™å·²å­˜å…¥ [æ­·å²] (ID: {w_id})")
                    else:
                        print(f"        â„¹ï¸ è³‡æ–™å·²å­˜åœ¨")

                except Exception as e:
                    print(f"    âš ï¸ è™•ç†é …ç›® {idx} æ™‚å‡ºéŒ¯: {e}")
                    traceback.print_exc()
                    continue

            print(f"    ğŸ“Š è™•ç† {processed_count} ç­†")
            return {'has_data': processed_count > 0, 'notices': [], 'processed': processed_count}

        except Exception as e:
            print(f"  âŒ è«‹æ±‚å¤±æ•—: {e}")
            traceback.print_exc()
            return {'has_data': False, 'notices': [], 'processed': 0}

    def scrape_all_pages(self, max_pages=5):
        print(f"\nğŸ‡¹ğŸ‡¼ é–‹å§‹çˆ¬å–å°ç£èˆªæ¸¯å±€èˆªè¡Œè­¦å‘Š...")
        print(f"  ğŸŒ ç›®æ¨™ç¶²å€: {self.base_url}")
        try:
            for category_id, category_name in self.target_categories.items():
                print(f"\n  ğŸ“‹ çˆ¬å–åˆ†é¡: {category_name} (ID: {category_id})")
                for page in range(1, max_pages + 1):
                    result = self.get_notices_selenium(page, category_id)
                    if not result['has_data']:
                        print(f"    ğŸ›‘ ç¬¬ {page} é æ²’æœ‰è³‡æ–™ï¼Œåœæ­¢")
                        break
                    if result['processed'] < 10:
                        print(f"    â„¹ï¸ ç¬¬ {page} é è³‡æ–™è¼ƒå°‘ï¼Œå¯èƒ½å·²æ¥è¿‘æœ€å¾Œä¸€é ")
                    time.sleep(2)
        except Exception as e:
            print(f"âŒ å°ç£èˆªæ¸¯å±€çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            traceback.print_exc()
        finally:
            try:
                self.driver.quit()
                print("  ğŸ”’ WebDriver å·²é—œé–‰ (å°ç£èˆªæ¸¯å±€)")
            except:
                pass

        total_new = len(self.new_warnings_today) + len(self.new_warnings_history)
        print(f"\nğŸ‡¹ğŸ‡¼ å°ç£èˆªæ¸¯å±€çˆ¬å–å®Œæˆ:")
        print(f"   ğŸ†• ä»Šæ—¥æ–°å¢: {len(self.new_warnings_today)} ç­†")
        print(f"   ğŸ“š æ­·å²è³‡æ–™: {len(self.new_warnings_history)} ç­†")
        print(f"   ğŸ“Š ç¸½è¨ˆ: {total_new} ç­†")
        return {'today': self.new_warnings_today, 'history': self.new_warnings_history}


# ==================== 7. ä¸­åœ‹æµ·äº‹å±€çˆ¬èŸ² (å¢å¼·ç‰ˆ) ====================
class CNMSANavigationWarningsScraper:
    def __init__(self, db_manager, keyword_manager, teams_notifier, coord_extractor, headless=True, days=3):
        self.db_manager      = db_manager
        self.keyword_manager = keyword_manager
        self.keywords        = keyword_manager.get_keywords()
        self.teams_notifier  = teams_notifier
        self.coord_extractor = coord_extractor

        print("ğŸ‡¨ğŸ‡³ åˆå§‹åŒ–ä¸­åœ‹æµ·äº‹å±€çˆ¬èŸ²...")

        options = webdriver.ChromeOptions()
        if headless:
            options.add_argument('--headless=new')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        prefs = {'profile.managed_default_content_settings.images': 2}
        options.add_experimental_option('prefs', prefs)
        options.add_experimental_option('excludeSwitches', ['enable-logging'])

        try:
            service = Service(ChromeDriverManager().install())
            if platform.system() == 'Windows':
                service.creation_flags = subprocess.CREATE_NO_WINDOW
            self.driver = webdriver.Chrome(service=service, options=options)
            self.driver.set_page_load_timeout(120)
            self.wait = WebDriverWait(self.driver, 15)
            print("  âœ… WebDriver å•Ÿå‹•æˆåŠŸ")
        except Exception as e:
            print(f"  âŒ WebDriver å•Ÿå‹•å¤±æ•—: {e}")
            raise

        self.days        = days
        self.cutoff_date = datetime.now() - timedelta(days=days)
        self.today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

        self.new_warnings_today        = []
        self.new_warnings_history      = []
        self.captured_warnings_today   = []
        self.captured_warnings_history = []

        print(f"  ğŸ“… ä¸­åœ‹æµ·äº‹å±€çˆ¬èŸ²è¨­å®š:")
        print(f"     - æŠ“å–ç¯„åœ: æœ€è¿‘ {days} å¤© (å¾ {self.cutoff_date.strftime('%Y-%m-%d')} èµ·)")
        print(f"     - ä»Šæ—¥å®šç¾©: {self.today_start.strftime('%Y-%m-%d')} 00:00 èµ·")

    def check_keywords(self, text):
        return [k for k in self.keywords if k.lower() in text.lower()]

    def parse_date(self, date_str):
        for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%Yå¹´%mæœˆ%dæ—¥']:
            try:
                return datetime.strptime(date_str.strip(), fmt)
            except:
                continue
        return None

    def scrape_bureau_warnings(self, bureau_name, bureau_element):
        """æŠ“å–å–®ä¸€æµ·äº‹å±€è­¦å‘Šï¼ˆå¢å¼·ç‰ˆï¼Œå€åˆ†ä»Šæ—¥/æ­·å²ï¼‰"""
        print(f"  ğŸ” æŠ“å–: {bureau_name}")

        max_retries = 3
        for retry in range(max_retries):
            try:
                if retry > 0:
                    print(f"    ğŸ”„ é‡è©¦ç¬¬ {retry} æ¬¡...")
                    try:
                        bureau_element = self.driver.find_element(
                            By.XPATH,
                            f"//div[@class='nav_lv2_text' and contains(text(), '{bureau_name}')]"
                        )
                    except:
                        print(f"    âš ï¸ ç„¡æ³•é‡æ–°ç²å–å…ƒç´ : {bureau_name}")
                        break

                self.driver.execute_script("arguments[0].scrollIntoView(true); arguments[0].click();", bureau_element)
                time.sleep(2)
                self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, "right_main")))

                processed_count = 0
                max_items = 100

                while processed_count < max_items:
                    try:
                        items = self.driver.find_elements(By.CSS_SELECTOR, ".right_main a")
                        if processed_count >= len(items):
                            break

                        item = items[processed_count]

                        try:
                            title = item.get_attribute('title') or item.text.strip()
                            title = re.sub(r'\s*\d{4}-\d{2}-\d{2}\s*$', '', title)
                            if not title:
                                processed_count += 1
                                continue

                            matched = self.check_keywords(title)
                            if not matched:
                                processed_count += 1
                                continue

                            link = item.get_attribute('href') or ''
                            if link.startswith('/'):
                                link = f"https://www.msa.gov.cn{link}"

                            try:
                                publish_time = item.find_element(By.CSS_SELECTOR, ".time").text.strip()
                            except:
                                match = re.search(r'\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}', item.text)
                                publish_time = match.group() if match else ""

                            is_today = False
                            if publish_time:
                                p_date = self.parse_date(publish_time)
                                if p_date:
                                    if p_date < self.cutoff_date:
                                        print(f"      â­ï¸ æ—¥æœŸéèˆŠ: {publish_time}")
                                        processed_count += 1
                                        continue
                                    is_today   = p_date >= self.today_start
                                    time_label = "ğŸ†• ä»Šæ—¥" if is_today else "ğŸ“š æ­·å²"
                                    print(f"      {time_label} è³‡æ–™: {publish_time}")
                                else:
                                    print(f"      âš ï¸ ç„¡æ³•è§£ææ—¥æœŸ: {publish_time}")
                                    processed_count += 1
                                    continue
                            else:
                                print(f"      âš ï¸ ç„¡æ—¥æœŸè³‡è¨Š")
                                processed_count += 1
                                continue

                            # â”€â”€ åº§æ¨™æå– â”€â”€
                            print(f"    ğŸ“ æ­£åœ¨æå–åº§æ¨™: {title[:40]}...")
                            coordinates = []
                            title_coords = self.coord_extractor.extract_coordinates(title)
                            if title_coords:
                                coordinates.extend(title_coords)
                                print(f"      âœ… å¾æ¨™é¡Œæå–åˆ° {len(title_coords)} å€‹åº§æ¨™")

                            if link and not link.startswith('javascript'):
                                try:
                                    self.driver.execute_script("window.open('');")
                                    self.driver.switch_to.window(self.driver.window_handles[-1])
                                    self.driver.set_page_load_timeout(10)
                                    try:
                                        self.driver.get(link)
                                        time.sleep(1)
                                        page_html   = self.driver.page_source
                                        page_coords = self.coord_extractor.extract_from_html(page_html)
                                        if page_coords:
                                            for pc in page_coords:
                                                if pc not in coordinates:
                                                    coordinates.append(pc)
                                            print(f"      âœ… å¾é é¢æå–åˆ° {len(page_coords)} å€‹åº§æ¨™")
                                    except Exception as e:
                                        print(f"      âš ï¸ é é¢è¼‰å…¥è¶…æ™‚æˆ–å¤±æ•—: {e}")
                                    finally:
                                        try:
                                            self.driver.close()
                                            self.driver.switch_to.window(self.driver.window_handles[0])
                                            self.driver.set_page_load_timeout(120)
                                        except:
                                            pass
                                except Exception as e:
                                    print(f"      âš ï¸ ç„¡æ³•å¾ç¶²é æå–åº§æ¨™: {e}")

                            if coordinates:
                                print(f"      ğŸ“ ç¸½å…±æå–åˆ° {len(coordinates)} å€‹åº§æ¨™")
                            else:
                                print(f"      âš ï¸ æœªæ‰¾åˆ°åº§æ¨™è³‡è¨Š")

                            db_data = (
                                bureau_name, title, link, publish_time,
                                ', '.join(matched),
                                datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                coordinates
                            )
                            is_new, w_id = self.db_manager.save_warning(db_data, source_type="CN_MSA")

                            if is_new and w_id:
                                warning_data = {
                                    'id': w_id, 'bureau': bureau_name, 'title': title,
                                    'link': link, 'time': publish_time, 'keywords': matched,
                                    'source': 'CN_MSA', 'coordinates': coordinates
                                }
                                if is_today:
                                    self.new_warnings_today.append(w_id)
                                    self.captured_warnings_today.append(warning_data)
                                    print(f"      âœ… æ–°è­¦å‘Š [ä»Šæ—¥]: {title[:40]}...")
                                else:
                                    self.new_warnings_history.append(w_id)
                                    self.captured_warnings_history.append(warning_data)
                                    print(f"      âœ… æ–°è­¦å‘Š [æ­·å²]: {title[:40]}...")
                            else:
                                print(f"      â­ï¸ å·²å­˜åœ¨")

                        except Exception as e:
                            print(f"    âš ï¸ è™•ç†é …ç›® {processed_count + 1} æ™‚å‡ºéŒ¯: {e}")

                        processed_count += 1

                    except Exception as e:
                        print(f"    âš ï¸ ç²å–é …ç›®åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
                        break

                print(f"    âœ… {bureau_name} è™•ç†å®Œæˆï¼Œå…±è™•ç† {processed_count} å€‹é …ç›®")
                break  # æˆåŠŸå‰‡è·³å‡ºé‡è©¦è¿´åœˆ

            except Exception as e:
                print(f"  âš ï¸ æŠ“å– {bureau_name} éŒ¯èª¤ (å˜—è©¦ {retry+1}/{max_retries}): {e}")
                if retry == max_retries - 1:
                    print(f"  âŒ {bureau_name} æŠ“å–å¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
                else:
                    time.sleep(3)

    def scrape_all_bureaus(self):
        print(f"\nğŸ‡¨ğŸ‡³ é–‹å§‹çˆ¬å–ä¸­åœ‹æµ·äº‹å±€èˆªè¡Œè­¦å‘Š...")
        try:
            print("  ğŸ“¡ æ­£åœ¨è¼‰å…¥ä¸­åœ‹æµ·äº‹å±€ç¶²ç«™...")
            self.driver.get('https://www.msa.gov.cn/page/outter/weather.jsp')
            time.sleep(5)

            print("  ğŸ–±ï¸ é»æ“Šèˆªè¡Œè­¦å‘Šé¸é …...")
            nav_btn = self.wait.until(
                EC.element_to_be_clickable((By.XPATH, "//span[contains(text(), 'èˆªè¡Œè­¦å‘Š')]"))
            )
            self.driver.execute_script("arguments[0].click();", nav_btn)
            time.sleep(3)

            print("  ğŸ“‹ ç²å–æµ·äº‹å±€åˆ—è¡¨...")
            bureaus = [
                b.text.strip()
                for b in self.driver.find_elements(By.CSS_SELECTOR, ".nav_lv2_list .nav_lv2_text")
                if b.text.strip()
            ]
            print(f"  ğŸ“ æ‰¾åˆ° {len(bureaus)} å€‹æµ·äº‹å±€")

            for b_name in bureaus:
                try:
                    elem = self.driver.find_element(
                        By.XPATH,
                        f"//div[@class='nav_lv2_text' and contains(text(), '{b_name}')]"
                    )
                    self.scrape_bureau_warnings(b_name, elem)
                    time.sleep(1)
                except Exception as e:
                    print(f"    âš ï¸ è·³é {b_name}: {e}")
                    continue

        except Exception as e:
            print(f"âŒ ä¸­åœ‹æµ·äº‹å±€çˆ¬å–éŒ¯èª¤: {e}")
            traceback.print_exc()
        finally:
            try:
                self.driver.quit()
                print("  ğŸ”’ WebDriver å·²é—œé–‰ (ä¸­åœ‹æµ·äº‹å±€)")
            except:
                pass

        total_new = len(self.new_warnings_today) + len(self.new_warnings_history)
        print(f"\nğŸ‡¨ğŸ‡³ ä¸­åœ‹æµ·äº‹å±€çˆ¬å–å®Œæˆ:")
        print(f"   ğŸ†• ä»Šæ—¥æ–°å¢: {len(self.new_warnings_today)} ç­†")
        print(f"   ğŸ“š æ­·å²è³‡æ–™: {len(self.new_warnings_history)} ç­†")
        print(f"   ğŸ“Š ç¸½è¨ˆ: {total_new} ç­†")
        return {'today': self.new_warnings_today, 'history': self.new_warnings_history}


# ==================== 8. ç’°å¢ƒè®Šæ•¸è®€å– ====================
print("ğŸ“‹ æ­£åœ¨è®€å–ç’°å¢ƒè®Šæ•¸...")

TEAMS_WEBHOOK    = os.getenv("TEAMS_WEBHOOK_URL", "")
MAIL_USER        = os.getenv("MAIL_USER", "")
MAIL_PASSWORD    = os.getenv("MAIL_PASSWORD", "")
TARGET_EMAIL     = os.getenv("TARGET_EMAIL", "")
MAIL_SMTP_SERVER = os.getenv("MAIL_SMTP_SERVER", "smtp.gmail.com")
MAIL_SMTP_PORT   = int(os.getenv("MAIL_SMTP_PORT", "587"))

DB_FILE_PATH     = os.getenv("DB_FILE_PATH", "navigation_warnings.db")
BACKUP_DIR       = os.getenv("BACKUP_DIR", "backups")
MAX_BACKUP_FILES = int(os.getenv("MAX_BACKUP_FILES", "7"))

SCRAPE_INTERVAL  = int(os.getenv("SCRAPE_INTERVAL", "3600"))
MAX_RETRIES      = int(os.getenv("MAX_RETRIES", "3"))
REQUEST_TIMEOUT  = int(os.getenv("REQUEST_TIMEOUT", "30"))

KEYWORDS_CONFIG  = os.getenv("KEYWORDS_CONFIG", "keywords_config.json")
CHROME_HEADLESS  = os.getenv("CHROME_HEADLESS", "true").lower() == "true"

ENABLE_EMAIL_NOTIFICATIONS = os.getenv("ENABLE_EMAIL_NOTIFICATIONS", "true").lower() == "true"
ENABLE_TEAMS_NOTIFICATIONS = os.getenv("ENABLE_TEAMS_NOTIFICATIONS", "true").lower() == "true"

ENABLE_CN_MSA = os.getenv("ENABLE_CN_MSA", "true").lower() == "true"
ENABLE_TW_MPB = os.getenv("ENABLE_TW_MPB", "true").lower() == "true"
ENABLE_UKMTO  = os.getenv("ENABLE_UKMTO",  "true").lower() == "true"   # â† æ–°å¢

SCRAPE_DAYS       = int(os.getenv("SCRAPE_DAYS",       "3"))
UKMTO_SCRAPE_DAYS = int(os.getenv("UKMTO_SCRAPE_DAYS", "30"))           # â† æ–°å¢ï¼ŒUKMTO é è¨­ 30 å¤©

print("\n" + "="*70)
print("âš™ï¸  ç³»çµ±è¨­å®šæª¢æŸ¥")
print("="*70)
print(f"ğŸ“§ Email é€šçŸ¥: {'âœ… å•Ÿç”¨' if ENABLE_EMAIL_NOTIFICATIONS and MAIL_USER else 'âŒ åœç”¨'}")
print(f"ğŸ“¢ Teams é€šçŸ¥: {'âœ… å•Ÿç”¨' if ENABLE_TEAMS_NOTIFICATIONS and TEAMS_WEBHOOK else 'âŒ åœç”¨'}")
print(f"ğŸ’¾ è³‡æ–™åº«: {DB_FILE_PATH}")
print(f"ğŸ“… æŠ“å–ç¯„åœ: CN/TW æœ€è¿‘ {SCRAPE_DAYS} å¤© | UKMTO æœ€è¿‘ {UKMTO_SCRAPE_DAYS} å¤©")
print(f"ğŸ” è³‡æ–™ä¾†æº: CN_MSA={'âœ…' if ENABLE_CN_MSA else 'âŒ'} | TW_MPB={'âœ…' if ENABLE_TW_MPB else 'âŒ'} | UKMTO={'âœ…' if ENABLE_UKMTO else 'âŒ'}")
print("="*70 + "\n")


# ==================== 9. ä¸»ç¨‹å¼é€²å…¥é» ====================
if __name__ == "__main__":
    try:
        print("\n" + "="*70)
        print("ğŸŒŠ æµ·äº‹è­¦å‘Šç›£æ§ç³»çµ±å•Ÿå‹• v3.0")
        print("="*70)

        # â”€â”€ åˆå§‹åŒ–è³‡æ–™åº« â”€â”€
        print("\nğŸ“¦ åˆå§‹åŒ–è³‡æ–™åº«...")
        db_manager = DatabaseManager(db_name=DB_FILE_PATH)
        print(f"  âœ… è³‡æ–™åº«åˆå§‹åŒ–æˆåŠŸ: {DB_FILE_PATH}")

        # â”€â”€ åˆå§‹åŒ–é—œéµå­—ç®¡ç†å™¨ â”€â”€
        print("ğŸ”‘ åˆå§‹åŒ–é—œéµå­—ç®¡ç†å™¨...")
        keyword_manager = KeywordManager(config_file=KEYWORDS_CONFIG)

        # â”€â”€ åˆå§‹åŒ–åº§æ¨™æå–å™¨ â”€â”€
        print("ğŸ—ºï¸  åˆå§‹åŒ–åº§æ¨™æå–å™¨...")
        coord_extractor = CoordinateExtractor()

        # â”€â”€ åˆå§‹åŒ– Teams é€šçŸ¥å™¨ â”€â”€
        teams_notifier = None
        if ENABLE_TEAMS_NOTIFICATIONS and TEAMS_WEBHOOK:
            print("ğŸ“¢ åˆå§‹åŒ– Teams é€šçŸ¥å™¨...")
            teams_notifier = UnifiedTeamsNotifier(TEAMS_WEBHOOK)

        # â”€â”€ åˆå§‹åŒ– Email é€šçŸ¥å™¨ â”€â”€
        email_notifier = None
        if ENABLE_EMAIL_NOTIFICATIONS and all([MAIL_USER, MAIL_PASSWORD, TARGET_EMAIL]):
            print("ğŸ“§ åˆå§‹åŒ– Email é€šçŸ¥å™¨...")
            email_notifier = GmailRelayNotifier(MAIL_USER, MAIL_PASSWORD, TARGET_EMAIL)

        # â”€â”€ åˆå§‹åŒ–çˆ¬èŸ² â”€â”€
        cn_scraper   = None
        tw_scraper   = None
        ukmto_scraper = None

        if ENABLE_CN_MSA:
            print("ğŸ‡¨ğŸ‡³ åˆå§‹åŒ–ä¸­åœ‹æµ·äº‹å±€çˆ¬èŸ²...")
            cn_scraper = CNMSANavigationWarningsScraper(
                db_manager=db_manager,
                keyword_manager=keyword_manager,
                teams_notifier=teams_notifier,
                coord_extractor=coord_extractor,
                headless=CHROME_HEADLESS,
                days=SCRAPE_DAYS
            )

        if ENABLE_TW_MPB:
            print("ğŸ‡¹ğŸ‡¼ åˆå§‹åŒ–å°ç£èˆªæ¸¯å±€çˆ¬èŸ²...")
            tw_scraper = TWMaritimePortBureauScraper(
                db_manager=db_manager,
                keyword_manager=keyword_manager,
                teams_notifier=teams_notifier,
                coord_extractor=coord_extractor,
                days=SCRAPE_DAYS
            )

        if ENABLE_UKMTO:
            print("ğŸ‡¬ğŸ‡§ åˆå§‹åŒ– UKMTO çˆ¬èŸ²...")
            ukmto_scraper = UKMTOScraper(
                db_manager=db_manager,
                keyword_manager=keyword_manager,
                teams_notifier=teams_notifier,
                coord_extractor=coord_extractor,
                days=UKMTO_SCRAPE_DAYS
            )

        print("\n" + "="*70)
        print("âœ… æ‰€æœ‰æ¨¡çµ„åˆå§‹åŒ–å®Œæˆ")
        print("="*70)

        # ========== é–‹å§‹çˆ¬å– ==========
        print("\nğŸš€ é–‹å§‹çˆ¬å–æµ·äº‹è­¦å‘Š...")

        all_warnings_today   = []
        all_warnings_history = []
        all_captured_today   = []
        all_captured_history = []

        # çˆ¬å–ä¸­åœ‹æµ·äº‹å±€
        if cn_scraper:
            print("\nğŸ‡¨ğŸ‡³ çˆ¬å–ä¸­åœ‹æµ·äº‹å±€...")
            cn_result = cn_scraper.scrape_all_bureaus()
            all_warnings_today.extend(cn_result['today'])
            all_warnings_history.extend(cn_result['history'])
            all_captured_today.extend(cn_scraper.captured_warnings_today)
            all_captured_history.extend(cn_scraper.captured_warnings_history)

        # çˆ¬å–å°ç£èˆªæ¸¯å±€
        if tw_scraper:
            print("\nğŸ‡¹ğŸ‡¼ çˆ¬å–å°ç£èˆªæ¸¯å±€...")
            tw_result = tw_scraper.scrape_all_pages()
            all_warnings_today.extend(tw_result['today'])
            all_warnings_history.extend(tw_result['history'])
            all_captured_today.extend(tw_scraper.captured_warnings_today)
            all_captured_history.extend(tw_scraper.captured_warnings_history)

        # çˆ¬å– UKMTO
        if ukmto_scraper:
            print("\nğŸ‡¬ğŸ‡§ çˆ¬å– UKMTO...")
            ukmto_result = ukmto_scraper.scrape()
            all_warnings_today.extend(ukmto_result['today'])
            all_warnings_history.extend(ukmto_result['history'])
            all_captured_today.extend(ukmto_scraper.captured_warnings_today)
            all_captured_history.extend(ukmto_scraper.captured_warnings_history)

        # ========== ç™¼é€é€šçŸ¥ ==========
        total_warnings = len(all_warnings_today) + len(all_warnings_history)

        if total_warnings > 0:
            print(f"\nğŸ“¢ ç™¼ç¾ {total_warnings} å€‹è­¦å‘Š (ä»Šæ—¥ {len(all_warnings_today)} ç­†ï¼Œæ­·å² {len(all_warnings_history)} ç­†)")

            if teams_notifier and ENABLE_TEAMS_NOTIFICATIONS:

                def _to_teams_tuple(w):
                    """å°‡ warning_data dict è½‰ç‚º Teams é€šçŸ¥æ‰€éœ€çš„ tuple æ ¼å¼"""
                    return (
                        w.get('id'),
                        w.get('bureau'),
                        w.get('title'),
                        w.get('link'),
                        w.get('time'),
                        ', '.join(w.get('keywords', [])) if isinstance(w.get('keywords'), list) else w.get('keywords', ''),
                        '',
                        json.dumps(w.get('coordinates', []))
                    )

                # ä¾ä¾†æºåˆ†çµ„ç™¼é€ï¼ˆä»Šæ—¥ï¼‰
                for src in ["CN_MSA", "TW_MPB", "UKMTO"]:
                    group = [w for w in all_captured_today if w.get('source') == src]
                    if group:
                        print(f"\nğŸ“¤ ç™¼é€ {src} é€šçŸ¥ [ä»Šæ—¥æ–°å¢]...")
                        teams_notifier.send_batch_notification(
                            [_to_teams_tuple(w) for w in group], src, is_today=True
                        )

                # ä¾ä¾†æºåˆ†çµ„ç™¼é€ï¼ˆæ­·å²ï¼‰
                for src in ["CN_MSA", "TW_MPB", "UKMTO"]:
                    group = [w for w in all_captured_history if w.get('source') == src]
                    if group:
                        print(f"\nğŸ“¤ ç™¼é€ {src} é€šçŸ¥ [æ­·å²è³‡æ–™]...")
                        teams_notifier.send_batch_notification(
                            [_to_teams_tuple(w) for w in group], src, is_today=False
                        )

            # Email é€šçŸ¥
            if email_notifier and ENABLE_EMAIL_NOTIFICATIONS:
                print("\nğŸ“§ ç™¼é€ Email é€šçŸ¥...")
                email_notifier.send_trigger_email(all_captured_today, all_captured_history)

        else:
            print("\nâœ… æ²’æœ‰æ–°çš„è­¦å‘Š")

        # ========== åŸ·è¡Œæ‘˜è¦ ==========
        print("\n" + "="*70)
        print("ğŸ“Š åŸ·è¡Œæ‘˜è¦")
        print("="*70)

        for src, icon in [("CN_MSA", "ğŸ‡¨ğŸ‡³ ä¸­åœ‹æµ·äº‹å±€"), ("TW_MPB", "ğŸ‡¹ğŸ‡¼ å°ç£èˆªæ¸¯å±€"), ("UKMTO", "ğŸ‡¬ğŸ‡§ UKMTO")]:
            t_count = len([w for w in all_captured_today   if w.get('source') == src])
            h_count = len([w for w in all_captured_history if w.get('source') == src])
            t_coords = sum(len(w.get('coordinates', [])) for w in all_captured_today   if w.get('source') == src)
            h_coords = sum(len(w.get('coordinates', [])) for w in all_captured_history if w.get('source') == src)
            print(f"\n  {icon}:")
            print(f"     ğŸ†• ä»Šæ—¥æ–°å¢: {t_count} ç­† ({t_coords} å€‹åº§æ¨™é»)")
            print(f"     ğŸ“š æ­·å²è³‡æ–™: {h_count} ç­† ({h_coords} å€‹åº§æ¨™é»)")

        total_coords = sum(len(w.get('coordinates', [])) for w in all_captured_today + all_captured_history)
        print(f"\n  ğŸ“ˆ ç¸½è¨ˆ: {total_warnings} ç­†è­¦å‘Š")
        print(f"  ğŸ“ ç¸½åº§æ¨™é»æ•¸: {total_coords}")

        print("\n" + "="*70)
        db_manager.print_statistics()

        print("\n" + "="*70)
        print("ğŸ‰ ç³»çµ±åŸ·è¡Œå®Œæˆ v3.0")
        print("="*70)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œå¤±æ•—: {e}")
        traceback.print_exc()

